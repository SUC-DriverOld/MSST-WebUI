import gradio as gr
import subprocess
import os
import sys
import re
import time
import shutil
import json
import requests
import yaml
import tkinter as tk
import librosa
import numpy as np
import pandas as pd
import webbrowser
import platform
import warnings
import locale
import threading
import psutil
from datetime import datetime
from ml_collections import ConfigDict
from tqdm import tqdm
from mir_eval.separation import bss_eval_sources
from tkinter import filedialog
from pydub import AudioSegment
from rich.console import Console
from torch import cuda, backends
from multiprocessing import cpu_count

PACKAGE_VERSION = "1.5.1"
WEBUI_CONFIG = "data/webui_config.json"
WEBUI_CONFIG_BACKUP = "data_backup/webui_config.json"
PRESETS = "data/preset_data.json"
MSST_MODEL = "data/msst_model_map.json"
VR_MODEL = "data/vr_model_map.json"
BACKUP = "backup/"
MODEL_FOLDER = "pretrain/"
TEMP_PATH = "temp"
UNOFFICIAL_MODEL = "config_unofficial"
MODEL_TYPE = ['bs_roformer', 'mel_band_roformer', 'segm_models', 'htdemucs', 'mdx23c', 'swin_upernet', 'bandit']
MODEL_CHOICES = ["vocal_models", "multi_stem_models", "single_stem_models", "UVR_VR_Models"]
FFMPEG = ".\\ffmpeg\\bin\\ffmpeg.exe" if os.path.isfile(".\\ffmpeg\\bin\\ffmpeg.exe") else "ffmpeg"
PYTHON = ".\\workenv\\python.exe" if os.path.isfile(".\\workenv\\python.exe") else sys.executable

language_dict = {
    "Auto": "Auto",
    "ç®€ä½“ä¸­æ–‡": "zh_CN",
    "ç¹é«”ä¸­æ–‡": "zh_TW",
    "English": "en_US",
    "æ—¥æœ¬èª": "ja_JP",
    "ğŸ˜Š": "emoji"
    }

warnings.filterwarnings("ignore")
stop_all_threads = False
stop_infer_flow = False

def setup_webui():
    def copy_folders():
        if os.path.exists("configs"):
            shutil.rmtree("configs")
        shutil.copytree("configs_backup", "configs")
        if os.path.exists("data"):
            shutil.rmtree("data")
        shutil.copytree("data_backup", "data")

    if not os.path.exists("data"):
        shutil.copytree("data_backup", "data")
        print(i18n("[INFO] æ­£åœ¨åˆå§‹åŒ–dataç›®å½•"))
    if not os.path.exists("configs"):
        shutil.copytree("configs_backup", "configs")
        print(i18n("[INFO] æ­£åœ¨åˆå§‹åŒ–configsç›®å½•"))
    if not os.path.exists("input"): os.makedirs("input")
    if not os.path.exists("results"): os.makedirs("results")
    if os.path.exists("data"):
        webui_config = load_configs(WEBUI_CONFIG)
        version = webui_config.get("version", None)
        if not version:
            try: version = load_configs("data/version.json")["version"]
            except Exception: 
                copy_folders()
                version = PACKAGE_VERSION
        if version != PACKAGE_VERSION:
            print(i18n("[INFO] æ£€æµ‹åˆ°") + version + i18n("æ—§ç‰ˆé…ç½®, æ­£åœ¨æ›´æ–°è‡³æœ€æ–°ç‰ˆ") + PACKAGE_VERSION)
            presets_config = load_configs(PRESETS)
            webui_config_backup = load_configs(WEBUI_CONFIG_BACKUP)
            for module in ["training", "inference", "tools", "settings"]:
                for key in webui_config_backup[module]:
                    try: webui_config_backup[module][key] = webui_config[module][key]
                    except KeyError: continue
            copy_folders()
            save_configs(webui_config_backup, WEBUI_CONFIG)
            save_configs(presets_config, PRESETS)

    os.environ["PATH"] += os.pathsep + os.path.abspath("ffmpeg/bin/")
    print(i18n("[INFO] è®¾å¤‡ä¿¡æ¯ï¼š") + str(get_device()))

    # fix model_path when version is lower than 1.5
    model_name = ["denoise_mel_band_roformer_aufr33_aggr_sdr_27.9768.ckpt", "denoise_mel_band_roformer_aufr33_sdr_27.9959.ckpt", "deverb_bs_roformer_8_256dim_8depth.ckpt", "deverb_bs_roformer_8_384dim_10depth.ckpt", "deverb_mel_band_roformer_ep_27_sdr_10.4567.ckpt"]
    for model in model_name:
        if os.path.exists(os.path.join(MODEL_FOLDER, "vocal_models", model)):
            shutil.move(os.path.join(MODEL_FOLDER, "vocal_models", model), os.path.join(MODEL_FOLDER, "single_stem_models", model))

def webui_restart():
    os.execl(PYTHON, PYTHON, *sys.argv)

def i18n(key):
    try:
        config = load_configs(WEBUI_CONFIG)
        if config["settings"]["language"]== "Auto":
            language = locale.getdefaultlocale()[0]
        else: language = config['settings']['language']
    except Exception:
        language = locale.getdefaultlocale()[0]
    if language == "zh_CN":
        return key
    if not os.path.exists(path=f"tools/i18n/locale/{language}.json"):
        language = "en_US"
    with open(file=f"tools/i18n/locale/{language}.json", mode="r", encoding="utf-8") as f:
        language_list = json.load(f)
    return language_list.get(key, key)

def get_device():
    try:
        if cuda.is_available():
            gpus = []
            n_gpu = cuda.device_count()
            for i in range(n_gpu):
                gpus.append(f"{i}: {cuda.get_device_name(i)}")
            if len(gpus) == 1:
                return gpus[0]
            return gpus
        elif backends.mps.is_available():
            return i18n("ä½¿ç”¨MPS")
        else:
            return i18n("æ— å¯ç”¨çš„åŠ é€Ÿè®¾å¤‡, ä½¿ç”¨CPU")
    except Exception:
        return i18n("è®¾å¤‡æ£€æŸ¥å¤±è´¥")

def get_platform():
    os_name = platform.system()
    os_version = platform.version()
    machine = platform.machine()
    return f"System: {os_name}, Version: {os_version}, Machine: {machine}"

def load_configs(config_path):
    if config_path.endswith('.json'):
        with open(config_path, 'r', encoding="utf-8") as f:
            return json.load(f)
    elif config_path.endswith('.yaml') or config_path.endswith('.yml'):
        with open(config_path, 'r') as f:
            return ConfigDict(yaml.load(f, Loader=yaml.FullLoader))

def save_configs(config, config_path):
    if config_path.endswith('.json'):
        with open(config_path, 'w', encoding="utf-8") as f:
            json.dump(config, f, indent=4)
    elif config_path.endswith('.yaml') or config_path.endswith('.yml'):
        with open(config_path, 'w') as f:
            yaml.dump(config.to_dict(), f)

def print_command(command):
    print("\033[32m" + "Use command: " + command + "\033[0m")

def load_augmentations_config():
    try:
        with open("configs/augmentations_template.yaml", 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return i18n("é”™è¯¯: æ— æ³•æ‰¾åˆ°å¢å¼ºé…ç½®æ–‡ä»¶æ¨¡æ¿, è¯·æ£€æŸ¥æ–‡ä»¶configs/augmentations_template.yamlæ˜¯å¦å­˜åœ¨ã€‚")

def load_selected_model(model_type=None):
    if not model_type:
        webui_config = load_configs(WEBUI_CONFIG)
        model_type = webui_config["inference"]["model_type"]
    if model_type:
        downloaded_model = []
        model_dir = os.path.join(MODEL_FOLDER, model_type)
        for files in os.listdir(model_dir):
            if files.endswith(('.ckpt', '.th', '.chpt')):
                downloaded_model.append(files)
        return downloaded_model
    return [i18n("è¯·é€‰æ‹©æ¨¡å‹ç±»å‹")]

def load_msst_model():
    config = load_configs(MSST_MODEL)
    model_list = []
    model_dir = [os.path.join(MODEL_FOLDER, keys) for keys in config.keys()]
    for dirs in model_dir:
        for files in os.listdir(dirs):
            if files.endswith(('.ckpt', '.th', '.chpt')):
                model_list.append(files)
    return model_list

def get_msst_model(model_name):
    config = load_configs(MSST_MODEL)
    webui_config = load_configs(WEBUI_CONFIG)
    main_link = webui_config['settings']['download_link']
    if main_link == "Auto":
        language = locale.getdefaultlocale()[0]
        if language in ["zh_CN", "zh_TW", "zh_HK", "zh_SG"]:
            main_link = "hf-mirror.com"
        else: main_link = "huggingface.co"
    for keys in config.keys():
        for model in config[keys]:
            if model["name"] == model_name:
                model_type = model["model_type"]
                model_path = os.path.join(MODEL_FOLDER, keys, model_name)
                config_path = model["config_path"]
                download_link = model["link"]
                try:
                    download_link = download_link.replace("huggingface.co", main_link)
                except: pass
                return model_path, config_path, model_type, download_link
    try:
        unofficial_config = load_configs(os.path.join(UNOFFICIAL_MODEL, "unofficial_msst_model.json"))
    except FileNotFoundError:
        raise gr.Error(i18n("æ¨¡å‹ä¸å­˜åœ¨!"))
    for keys in unofficial_config.keys():
        for model in unofficial_config[keys]:
            if model["name"] == model_name:
                model_type = model["model_type"]
                model_path = os.path.join(MODEL_FOLDER, keys, model_name)
                config_path = model["config_path"]
                download_link = model["link"]
                return model_path, config_path, model_type, download_link
    raise gr.Error(i18n("æ¨¡å‹ä¸å­˜åœ¨!"))

def load_vr_model():
    downloaded_model = []
    config = load_configs(WEBUI_CONFIG)
    vr_model_path = config['settings']['uvr_model_dir']
    for files in os.listdir(vr_model_path):
        if files.endswith('.pth'):
            downloaded_model.append(files)
    return downloaded_model

def get_vr_model(model):
    config = load_configs(VR_MODEL)
    webui_config = load_configs(WEBUI_CONFIG)
    model_path = webui_config['settings']['uvr_model_dir']
    main_link = webui_config['settings']['download_link']
    if main_link == "Auto":
        language = locale.getdefaultlocale()[0]
        if language in ["zh_CN", "zh_TW", "zh_HK", "zh_SG"]:
            main_link = "hf-mirror.com"
        else: main_link = "huggingface.co"
    for keys in config.keys():
        if keys == model:
            primary_stem = config[keys]["primary_stem"]
            secondary_stem = config[keys]["secondary_stem"]
            model_url = config[keys]["download_link"]
            try:
                model_url = model_url.replace("huggingface.co", main_link)
            except: pass
            return primary_stem, secondary_stem, model_url, model_path
    try:
        unofficial_config = load_configs(os.path.join(UNOFFICIAL_MODEL, "unofficial_vr_model.json"))
    except FileNotFoundError:
        raise gr.Error(i18n("æ¨¡å‹ä¸å­˜åœ¨!"))
    for keys in unofficial_config.keys():
        if keys == model:
            primary_stem = unofficial_config[keys]["primary_stem"]
            secondary_stem = unofficial_config[keys]["secondary_stem"]
            model_url = unofficial_config[keys]["download_link"]
            return primary_stem, secondary_stem, model_url, model_path
    raise gr.Error(i18n("æ¨¡å‹ä¸å­˜åœ¨!"))

def load_vr_model_stem(model):
    primary_stem, secondary_stem, _, _= get_vr_model(model)
    return gr.Checkbox(label=f"{primary_stem} Only", value=False, interactive=True), gr.Checkbox(label=f"{secondary_stem} Only", value=False, interactive=True)

def select_folder():
    root = tk.Tk()
    root.withdraw()
    root.attributes('-topmost', True)
    selected_dir = filedialog.askdirectory()
    root.destroy()
    return selected_dir

def select_yaml_file():
    root = tk.Tk()
    root.withdraw()
    root.attributes('-topmost', True)
    selected_file = filedialog.askopenfilename(
        filetypes=[('YAML files', '*.yaml')])
    root.destroy()
    return selected_file

def select_file():
    root = tk.Tk()
    root.withdraw()
    root.attributes('-topmost', True)
    selected_file = filedialog.askopenfilename(
        filetypes=[('All files', '*.*')])
    root.destroy()
    return selected_file

def open_folder(folder):
    if folder == "":
        raise gr.Error(i18n("è¯·å…ˆé€‰æ‹©æ–‡ä»¶å¤¹!"))
    if not os.path.exists(folder):
        os.makedirs(folder)
    absolute_path = os.path.abspath(folder)
    if platform.system() == "Windows":
        os.system(f"explorer {absolute_path}")
    elif platform.system() == "Darwin":
        os.system(f"open {absolute_path}")
    else:
        os.system(f"xdg-open {absolute_path}")

def save_training_config(train_model_type, train_config_path, train_dataset_type, train_dataset_path, train_valid_path, train_num_workers, train_device_ids, train_seed, train_pin_memory, train_use_multistft_loss, train_use_mse_loss, train_use_l1_loss, train_results_path, train_accelerate, train_pre_validate):
    config = load_configs(WEBUI_CONFIG)
    config['training']['model_type'] = train_model_type
    config['training']['config_path'] = train_config_path
    config['training']['dataset_type'] = train_dataset_type
    config['training']['dataset_path'] = train_dataset_path
    config['training']['valid_path'] = train_valid_path
    config['training']['num_workers'] = train_num_workers
    config['training']['device_ids'] = train_device_ids
    config['training']['seed'] = train_seed
    config['training']['pin_memory'] = train_pin_memory
    config['training']['use_multistft_loss'] = train_use_multistft_loss
    config['training']['use_mse_loss'] = train_use_mse_loss
    config['training']['use_l1_loss'] = train_use_l1_loss
    config['training']['accelerate'] = train_accelerate
    config['training']['pre_valid'] = train_pre_validate
    config['training']['results_path'] = train_results_path
    save_configs(config, WEBUI_CONFIG)
    return i18n("é…ç½®ä¿å­˜æˆåŠŸ!")

def save_vr_inference_config(vr_select_model, vr_window_size, vr_aggression, vr_output_format, vr_use_cpu, vr_primary_stem_only, vr_secondary_stem_only, vr_multiple_audio_input, vr_store_dir, vr_batch_size, vr_normalization, vr_post_process_threshold, vr_invert_spect, vr_enable_tta, vr_high_end_process, vr_enable_post_process, vr_debug_mode):
    config = load_configs(WEBUI_CONFIG)
    config['inference']['vr_select_model'] = vr_select_model
    config['inference']['vr_window_size'] = vr_window_size
    config['inference']['vr_aggression'] = vr_aggression
    config['inference']['vr_output_format'] = vr_output_format
    config['inference']['vr_use_cpu'] = vr_use_cpu
    config['inference']['vr_primary_stem_only'] = vr_primary_stem_only
    config['inference']['vr_secondary_stem_only'] = vr_secondary_stem_only
    config['inference']['vr_multiple_audio_input'] = vr_multiple_audio_input
    config['inference']['vr_store_dir'] = vr_store_dir
    config['inference']['vr_batch_size'] = vr_batch_size
    config['inference']['vr_normalization'] = vr_normalization
    config['inference']['vr_post_process_threshold'] = vr_post_process_threshold
    config['inference']['vr_invert_spect'] = vr_invert_spect
    config['inference']['vr_enable_tta'] = vr_enable_tta
    config['inference']['vr_high_end_process'] = vr_high_end_process
    config['inference']['vr_enable_post_process'] = vr_enable_post_process
    config['inference']['vr_debug_mode'] = vr_debug_mode
    save_configs(config, WEBUI_CONFIG)

def save_msst_inference_config(selected_model, input_folder, store_dir, extract_instrumental, gpu_id, output_format, force_cpu, use_tta):
    config = load_configs(WEBUI_CONFIG)
    config['inference']['selected_model'] = selected_model
    config['inference']['gpu_id'] = gpu_id
    config['inference']['output_format'] = output_format
    config['inference']['force_cpu'] = force_cpu
    config['inference']['extract_instrumental'] = extract_instrumental
    config['inference']['use_tta'] = use_tta
    config['inference']['store_dir'] = store_dir
    config['inference']['multiple_audio_input'] = input_folder
    save_configs(config, WEBUI_CONFIG)

def save_uvr_modeldir(select_uvr_model_dir):
    if not os.path.exists(select_uvr_model_dir):
        return i18n("è¯·é€‰æ‹©æ­£ç¡®çš„æ¨¡å‹ç›®å½•")
    config = load_configs(WEBUI_CONFIG)
    config['settings']['uvr_model_dir'] = select_uvr_model_dir
    save_configs(config, WEBUI_CONFIG)
    return i18n("è®¾ç½®ä¿å­˜æˆåŠŸ! è¯·é‡å¯WebUIä»¥åº”ç”¨ã€‚")

def reset_settings():
    try:
        config = load_configs(WEBUI_CONFIG)
        config_backup = load_configs(WEBUI_CONFIG_BACKUP)
        for key in config_backup['settings'][key]:
            config['settings'][key] = config_backup['settings'][key]
        save_configs(config, WEBUI_CONFIG)
        return i18n("è®¾ç½®é‡ç½®æˆåŠŸ, è¯·é‡å¯WebUIåˆ·æ–°! ")
    except Exception as e:
        print(e)
        return i18n("è®¾ç½®é‡ç½®å¤±è´¥!")

def reset_webui_config():
    try:
        config = load_configs(WEBUI_CONFIG)
        config_backup = load_configs(WEBUI_CONFIG_BACKUP)
        for key in config_backup['training'][key]:
            config['training'][key] = config_backup['training'][key]
        for key in config_backup['inference'][key]:
            config['inference'][key] = config_backup['inference'][key]
        for key in config_backup['tools'][key]:
            config['tools'][key] = config_backup['tools'][key]
        save_configs(config, WEBUI_CONFIG)
        return i18n("è®°å½•é‡ç½®æˆåŠŸ, è¯·é‡å¯WebUIåˆ·æ–°! ")
    except Exception as e:
        print(e)
        return i18n("è®°å½•é‡ç½®å¤±è´¥!")

def init_selected_model():
    try:
        batch_size, dim_t, num_overlap = i18n("è¯¥æ¨¡å‹ä¸æ”¯æŒä¿®æ”¹æ­¤å€¼"), i18n("è¯¥æ¨¡å‹ä¸æ”¯æŒä¿®æ”¹æ­¤å€¼"), i18n("è¯¥æ¨¡å‹ä¸æ”¯æŒä¿®æ”¹æ­¤å€¼")
        config = load_configs(WEBUI_CONFIG)
        selected_model = config['inference']['selected_model']
        _, config_path, _, _ = get_msst_model(selected_model)
        config = load_configs(config_path)
        if config.inference.get('batch_size'):
            batch_size = config.inference.get('batch_size')
        if config.inference.get('dim_t'):
            dim_t = config.inference.get('dim_t')
        if config.inference.get('num_overlap'):
            num_overlap = config.inference.get('num_overlap')
        return batch_size, dim_t, num_overlap
    except: return i18n("è¯·å…ˆé€‰æ‹©æ¨¡å‹"), i18n("è¯·å…ˆé€‰æ‹©æ¨¡å‹"), i18n("è¯·å…ˆé€‰æ‹©æ¨¡å‹")

def init_selected_vr_model():
    webui_config = load_configs(WEBUI_CONFIG)
    config = load_configs(VR_MODEL)
    model = webui_config['inference']['vr_select_model']
    if not model:
        vr_primary_stem_only = i18n("ä»…è¾“å‡ºä¸»éŸ³è½¨")
        vr_secondary_stem_only = i18n("ä»…è¾“å‡ºæ¬¡éŸ³è½¨")
        return vr_primary_stem_only, vr_secondary_stem_only
    primary_stem, secondary_stem, _, _ = get_vr_model(model)
    vr_primary_stem_only = f"{primary_stem} Only"
    vr_secondary_stem_only = f"{secondary_stem} Only"
    return vr_primary_stem_only, vr_secondary_stem_only

def update_train_start_check_point(path):
    if not os.path.isdir(path):
        raise gr.Error(i18n("è¯·å…ˆé€‰æ‹©æ¨¡å‹ä¿å­˜è·¯å¾„! "))
    ckpt_files = [f for f in os.listdir(path) if f.endswith(('.ckpt', '.chpt', '.th'))]
    return gr.Dropdown(label=i18n("åˆå§‹æ¨¡å‹"), choices=ckpt_files if ckpt_files else ["None"])

def update_selected_model(model_type):
    webui_config = load_configs(WEBUI_CONFIG)
    webui_config["inference"]["model_type"] = model_type
    save_configs(webui_config, WEBUI_CONFIG)
    return gr.Dropdown(label=i18n("é€‰æ‹©æ¨¡å‹"), choices=load_selected_model(), value=None, interactive=True, scale=4)

def update_inference_settings(selected_model):
    batch_size = gr.Textbox(label="batch_size", value=i18n("è¯¥æ¨¡å‹ä¸æ”¯æŒä¿®æ”¹æ­¤å€¼"), interactive=False)
    dim_t = gr.Textbox(label="dim_t", value=i18n("è¯¥æ¨¡å‹ä¸æ”¯æŒä¿®æ”¹æ­¤å€¼"), interactive=False)
    num_overlap = gr.Textbox(label="num_overlap", value=i18n("è¯¥æ¨¡å‹ä¸æ”¯æŒä¿®æ”¹æ­¤å€¼"), interactive=False)
    normalize = gr.Checkbox(label=i18n("normalize (è¯¥æ¨¡å‹ä¸æ”¯æŒä¿®æ”¹æ­¤å€¼) "), value=False, interactive=False)
    if selected_model and selected_model !="":
        _, config_path, _, _ = get_msst_model(selected_model)
        config = load_configs(config_path)
        if config.inference.get('batch_size'):
            batch_size = gr.Textbox(label="batch_size", value=str(config.inference.get('batch_size')), interactive=True)
        if config.inference.get('dim_t'):
            dim_t = gr.Textbox(label="dim_t", value=str(config.inference.get('dim_t')), interactive=True)
        if config.inference.get('num_overlap'):
            num_overlap = gr.Textbox(label="num_overlap", value=str(config.inference.get('num_overlap')), interactive=True)
        if config.inference.get('normalize'):
            normalize = gr.Checkbox(label="normalize", value=config.inference.get('normalize'), interactive=True)
    return batch_size, dim_t, num_overlap, normalize

def save_config(selected_model, batch_size, dim_t, num_overlap, normalize):
    _, config_path, _, _ = get_msst_model(selected_model)
    config = load_configs(config_path)
    if config.inference.get('batch_size'):
        config.inference['batch_size'] = int(batch_size) if batch_size.isdigit() else None
    if config.inference.get('dim_t'):
        config.inference['dim_t'] = int(dim_t) if dim_t.isdigit() else None
    if config.inference.get('num_overlap'):
        config.inference['num_overlap'] = int(num_overlap) if num_overlap.isdigit() else None
    if config.inference.get('normalize'):
        config.inference['normalize'] = normalize
    save_configs(config, config_path)
    return i18n("é…ç½®ä¿å­˜æˆåŠŸ!")

def reset_config(selected_model):
    _, original_config_path, _, _ = get_msst_model(selected_model)
    if original_config_path.startswith(UNOFFICIAL_MODEL):
        return i18n("éå®˜æ–¹æ¨¡å‹ä¸æ”¯æŒé‡ç½®é…ç½®!")
    dir_path, file_name = os.path.split(original_config_path)
    backup_dir_path = dir_path.replace("configs", "configs_backup", 1)
    backup_config_path = os.path.join(backup_dir_path, file_name)
    if os.path.exists(backup_config_path):
        shutil.copy(backup_config_path, original_config_path)
        update_inference_settings(selected_model)
        return i18n("é…ç½®é‡ç½®æˆåŠŸ!")
    else:
        return i18n("å¤‡ä»½é…ç½®æ–‡ä»¶ä¸å­˜åœ¨!")

def run_command(command):
    global stop_all_threads
    stop_all_threads = False
    print_command(command)
    try:
        process = subprocess.Popen(command, shell=True)
        proc = psutil.Process(process.pid)
        while process.poll() is None:
            if stop_all_threads:
                for child in proc.children(recursive=True):
                    child.terminate()
                process.terminate()
                stop_all_threads = False
                return
        if process.returncode != 0:
            gr.Error(i18n("å‘ç”Ÿé”™è¯¯! è¯·å‰å¾€ç»ˆç«¯æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯"))
    except Exception as e:
        print(e)
        raise gr.Error(i18n("å‘ç”Ÿé”™è¯¯! è¯·å‰å¾€ç»ˆç«¯æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯"))

def stop_all_thread():
    global stop_all_threads, stop_infer_flow
    for thread in threading.enumerate():
        if thread.name in ["msst_inference", "vr_inference", "msst_training", "msst_valid"]:
            stop_all_threads = True
            stop_infer_flow = True
            gr.Info(i18n("å·²åœæ­¢è¿›ç¨‹"))
            print(i18n("å·²åœæ­¢è¿›ç¨‹"))

def run_inference_single(selected_model, input_audio, store_dir, extract_instrumental, gpu_id, output_format, force_cpu, use_tta):
    input_folder = None
    if not input_audio:
        return i18n("è¯·ä¸Šä¼ ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ã€‚")
    if os.path.exists(TEMP_PATH):
        shutil.rmtree(TEMP_PATH)
    os.makedirs(TEMP_PATH)
    shutil.copy(input_audio, TEMP_PATH)
    input_path = TEMP_PATH
    save_msst_inference_config(selected_model, input_folder, store_dir, extract_instrumental, gpu_id, output_format, force_cpu, use_tta)
    run_inference(selected_model, input_path, store_dir,extract_instrumental, gpu_id, output_format, force_cpu, use_tta)
    return i18n("å¤„ç†å®Œæˆ! åˆ†ç¦»å®Œæˆçš„éŸ³é¢‘æ–‡ä»¶å·²ä¿å­˜åœ¨") + store_dir

def run_multi_inference(selected_model, input_folder, store_dir, extract_instrumental, gpu_id, output_format, force_cpu, use_tta):
    save_msst_inference_config(selected_model, input_folder, store_dir, extract_instrumental, gpu_id, output_format, force_cpu, use_tta)
    run_inference(selected_model, input_folder, store_dir,extract_instrumental, gpu_id, output_format, force_cpu, use_tta)
    return i18n("å¤„ç†å®Œæˆ! åˆ†ç¦»å®Œæˆçš„éŸ³é¢‘æ–‡ä»¶å·²ä¿å­˜åœ¨") + store_dir

def run_inference(selected_model, input_folder, store_dir, extract_instrumental, gpu_id, output_format, force_cpu, use_tta, extra_store_dir=None):
    if not bool(re.match(r'^(\d+)(?:\s(?!\1)\d+)*$', gpu_id)):
        raise gr.Error(i18n("GPU IDæ ¼å¼é”™è¯¯, è¯·é‡æ–°è¾“å…¥"))
    if selected_model == "":
        raise gr.Error(i18n("è¯·é€‰æ‹©æ¨¡å‹"))
    if input_folder == "":
        raise gr.Error(i18n("è¯·é€‰æ‹©è¾“å…¥ç›®å½•"))
    if not os.path.exists(store_dir):
        os.makedirs(store_dir)
    if extra_store_dir and not os.path.exists(extra_store_dir):
        os.makedirs(extra_store_dir)
    start_check_point, config_path, model_type, _ = get_msst_model(selected_model)
    gpu_ids = gpu_id if not force_cpu else "0"
    extract_instrumental_option = "--extract_instrumental" if extract_instrumental else ""
    force_cpu_option = "--force_cpu" if force_cpu else ""
    use_tta_option = "--use_tta" if use_tta else ""
    extra_store_dir = f"--extra_store_dir \"{extra_store_dir}\"" if extra_store_dir else ""
    command = f"{PYTHON} msst_inference.py --model_type {model_type} --config_path \"{config_path}\" --start_check_point \"{start_check_point}\" --input_folder \"{input_folder}\" --store_dir \"{store_dir}\" --device_ids {gpu_ids} --output_format {output_format} {extract_instrumental_option} {force_cpu_option} {use_tta_option} {extra_store_dir}"
    msst_inference = threading.Thread(target=run_command, args=(command,), name="msst_inference")
    msst_inference.start()
    msst_inference.join()

def vr_inference_single(vr_select_model, vr_window_size, vr_aggression, vr_output_format, vr_use_cpu, vr_primary_stem_only, vr_secondary_stem_only, vr_single_audio, vr_store_dir, vr_batch_size, vr_normalization, vr_post_process_threshold, vr_invert_spect, vr_enable_tta, vr_high_end_process, vr_enable_post_process, vr_debug_mode):
    vr_multiple_audio_input = None
    if not os.path.isfile(vr_single_audio):
        return i18n("è¯·ä¸Šä¼ ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶")
    if not vr_select_model:
        return i18n("è¯·é€‰æ‹©æ¨¡å‹")
    if not vr_store_dir:
        return i18n("è¯·é€‰æ‹©è¾“å‡ºç›®å½•")
    if not os.path.exists(vr_store_dir):
        os.makedirs(vr_store_dir)
    if os.path.exists(TEMP_PATH):
        shutil.rmtree(TEMP_PATH)
    os.makedirs(TEMP_PATH)
    shutil.copy(vr_single_audio, TEMP_PATH)
    vr_single_audio = os.path.join(TEMP_PATH, os.path.basename(vr_single_audio))
    save_vr_inference_config(vr_select_model, vr_window_size, vr_aggression, vr_output_format, vr_use_cpu, vr_primary_stem_only, vr_secondary_stem_only, vr_multiple_audio_input, vr_store_dir, vr_batch_size, vr_normalization, vr_post_process_threshold, vr_invert_spect, vr_enable_tta, vr_high_end_process, vr_enable_post_process, vr_debug_mode)
    vr_inference(vr_select_model, vr_window_size, vr_aggression, vr_output_format, vr_use_cpu, vr_primary_stem_only, vr_secondary_stem_only, vr_single_audio, vr_store_dir, vr_batch_size, vr_normalization, vr_post_process_threshold, vr_invert_spect, vr_enable_tta, vr_high_end_process, vr_enable_post_process, vr_debug_mode)
    return i18n("å¤„ç†å®Œæˆ, ç»“æœå·²ä¿å­˜è‡³") + vr_store_dir

def vr_inference_multi(vr_select_model, vr_window_size, vr_aggression, vr_output_format, vr_use_cpu, vr_primary_stem_only, vr_secondary_stem_only, vr_multiple_audio_input, vr_store_dir, vr_batch_size, vr_normalization, vr_post_process_threshold, vr_invert_spect, vr_enable_tta, vr_high_end_process, vr_enable_post_process, vr_debug_mode):
    if not os.path.isdir(vr_multiple_audio_input):
        return i18n("è¯·é€‰æ‹©è¾“å…¥æ–‡ä»¶å¤¹")
    if not vr_select_model:
        return i18n("è¯·é€‰æ‹©æ¨¡å‹")
    if not vr_store_dir:
        return i18n("è¯·é€‰æ‹©è¾“å‡ºç›®å½•")
    if not os.path.exists(vr_store_dir):
        os.makedirs(vr_store_dir)
    save_vr_inference_config(vr_select_model, vr_window_size, vr_aggression, vr_output_format, vr_use_cpu, vr_primary_stem_only, vr_secondary_stem_only, vr_multiple_audio_input, vr_store_dir, vr_batch_size, vr_normalization, vr_post_process_threshold, vr_invert_spect, vr_enable_tta, vr_high_end_process, vr_enable_post_process, vr_debug_mode)
    vr_inference(vr_select_model, vr_window_size, vr_aggression, vr_output_format, vr_use_cpu, vr_primary_stem_only, vr_secondary_stem_only, vr_multiple_audio_input, vr_store_dir, vr_batch_size, vr_normalization, vr_post_process_threshold, vr_invert_spect, vr_enable_tta, vr_high_end_process, vr_enable_post_process, vr_debug_mode)
    return i18n("å¤„ç†å®Œæˆ, ç»“æœå·²ä¿å­˜è‡³") + vr_store_dir

def vr_inference(vr_select_model, vr_window_size, vr_aggression, vr_output_format, vr_use_cpu, vr_primary_stem_only, vr_secondary_stem_only, vr_audio_input, vr_store_dir, vr_batch_size, vr_normalization, vr_post_process_threshold, vr_invert_spect, vr_enable_tta, vr_high_end_process, vr_enable_post_process, vr_debug_mode, save_another_stem=False, extra_output_dir=None):
    primary_stem, secondary_stem, _, model_file_dir = get_vr_model(vr_select_model)
    audio_file = vr_audio_input
    model_filename = vr_select_model
    output_format = vr_output_format
    output_dir = vr_store_dir
    invert_spect = "--invert_spect" if vr_invert_spect else ""
    normalization = vr_normalization
    debug_mode = "--debug" if vr_debug_mode else ""
    if vr_primary_stem_only:
        if vr_secondary_stem_only:
            single_stem = ""
        else:
            single_stem = f"--single_stem \"{primary_stem}\""
    else:
        if vr_secondary_stem_only:
            single_stem = f"--single_stem \"{secondary_stem}\""
        else:
            single_stem = ""
    vr_batch_size = int(vr_batch_size)
    vr_aggression = int(vr_aggression)
    use_cpu = "--use_cpu" if vr_use_cpu else ""
    vr_enable_tta = "--vr_enable_tta" if vr_enable_tta else ""
    vr_high_end_process = "--vr_high_end_process" if vr_high_end_process else ""
    vr_enable_post_process = "--vr_enable_post_process" if vr_enable_post_process else ""
    save_another_stem = "--save_another_stem" if save_another_stem else ""
    extra_output_dir = f"--extra_output_dir \"{extra_output_dir}\"" if extra_output_dir else ""
    command = f"{PYTHON} uvr_inference.py \"{audio_file}\" {debug_mode} --model_filename \"{model_filename}\" --output_format {output_format} --output_dir \"{output_dir}\" --model_file_dir \"{model_file_dir}\" {invert_spect} --normalization {normalization} {single_stem} {use_cpu} --vr_batch_size {vr_batch_size} --vr_window_size {vr_window_size} --vr_aggression {vr_aggression} {vr_enable_tta} {vr_high_end_process} {vr_enable_post_process} --vr_post_process_threshold {vr_post_process_threshold} {save_another_stem} {extra_output_dir}"
    vr_inference = threading.Thread(target=run_command, args=(command,), name="vr_inference")
    vr_inference.start()
    vr_inference.join()

def update_model_name(model_type):
    if model_type == "UVR_VR_Models":
        model_map = load_vr_model()
        return gr.Dropdown(label=i18n("é€‰æ‹©æ¨¡å‹"), choices=model_map, interactive=True)
    else:
        model_map = load_selected_model(model_type)
        return gr.Dropdown(label=i18n("é€‰æ‹©æ¨¡å‹"), choices=model_map, interactive=True)

def update_model_stem(model_type, model_name):
    if model_type == "UVR_VR_Models":
        primary_stem, secondary_stem, _, _ = get_vr_model(model_name)
        return gr.Dropdown(label=i18n("è¾“å‡ºéŸ³è½¨"), choices=[primary_stem, secondary_stem], interactive=True)
    else:
        return gr.Dropdown(label=i18n("è¾“å‡ºéŸ³è½¨"), choices=["primary_stem"], value="primary_stem", interactive=False)

def add_to_flow_func(model_type, model_name, stem, secondary_output, df):
    if not model_type or not model_name:
        return df
    if model_type == "UVR_VR_Models" and not stem:
        return df
    if model_type == "UVR_VR_Models" and stem == "primary_stem":
        return df
    if not secondary_output or secondary_output == "":
        secondary_output = "False"
    new_data = pd.DataFrame({"model_type": [model_type], "model_name": [model_name], "stem": [stem], "secondary_output": [secondary_output]})
    if df["model_type"].iloc[0] == "" or df["model_name"].iloc[0] == "":
        return new_data
    updated_df = pd.concat([df, new_data], ignore_index=True)
    return updated_df

def save_flow_func(preset_name, df):
    preset_data = load_configs(PRESETS)
    if preset_name is None or preset_name == "":
        output_message = i18n("è¯·å¡«å†™é¢„è®¾åç§°")
        preset_name_delete = gr.Dropdown(label=i18n("è¯·é€‰æ‹©é¢„è®¾"), choices=list(preset_data.keys()))
        preset_name_select = gr.Dropdown(label=i18n("è¯·é€‰æ‹©é¢„è®¾"), choices=list(preset_data.keys()))
        return output_message, preset_name_delete, preset_name_select
    preset_dict = {f"Step_{index + 1}": row.dropna().to_dict() for index, row in df.iterrows()}
    preset_data[preset_name] = preset_dict
    save_configs(preset_data, PRESETS)
    output_message = i18n("é¢„è®¾") + preset_name + i18n("ä¿å­˜æˆåŠŸ")
    preset_name_delete = gr.Dropdown(label=i18n("è¯·é€‰æ‹©é¢„è®¾"), choices=list(preset_data.keys()))
    preset_name_select = gr.Dropdown(label=i18n("è¯·é€‰æ‹©é¢„è®¾"), choices=list(preset_data.keys()))
    return output_message, preset_name_delete, preset_name_select

def reset_flow_func():
    return gr.Dataframe(pd.DataFrame({"model_type": [""], "model_name": [""], "stem": [""]}), interactive=False, label=None)

def load_preset(preset_name):
    preset_data = load_configs(PRESETS)
    if preset_name in preset_data.keys():
        preset_flow = pd.DataFrame({"model_type": [""], "model_name": [""], "stem": [""], "secondary_output": [""]})
        preset_dict = preset_data[preset_name]
        for key in preset_dict.keys():
            try:
                secondary_output = preset_dict[key]["secondary_output"]
            except KeyError:
                secondary_output = "False"
            preset_flow = add_to_flow_func(preset_dict[key]["model_type"], preset_dict[key]["model_name"], preset_dict[key]["stem"], secondary_output, preset_flow)
        return preset_flow
    return gr.Dataframe(pd.DataFrame({"model_type": [i18n("é¢„è®¾ä¸å­˜åœ¨")], "model_name": [i18n("é¢„è®¾ä¸å­˜åœ¨")], "stem": [i18n("é¢„è®¾ä¸å­˜åœ¨")], "secondary_output": [i18n("é¢„è®¾ä¸å­˜åœ¨")]}), interactive=False, label=None)

def delete_func(preset_name):
    preset_data = load_configs(PRESETS)
    if preset_name in preset_data.keys():
        _, select_preset_backup = backup_preset_func()
        del preset_data[preset_name]
        save_configs(preset_data, PRESETS)
        output_message = i18n("é¢„è®¾") + preset_name + i18n("åˆ é™¤æˆåŠŸ")
        preset_name_delete = gr.Dropdown(label=i18n("è¯·é€‰æ‹©é¢„è®¾"), choices=list(preset_data.keys()))
        preset_name_select = gr.Dropdown(label=i18n("è¯·é€‰æ‹©é¢„è®¾"), choices=list(preset_data.keys()))
        preset_flow_delete = gr.Dataframe(pd.DataFrame({"model_type": [i18n("é¢„è®¾å·²åˆ é™¤")], "model_name": [i18n("é¢„è®¾å·²åˆ é™¤")], "stem": [i18n("é¢„è®¾å·²åˆ é™¤")], "secondary_output": [i18n("é¢„è®¾å·²åˆ é™¤")]}), interactive=False, label=None)
        return output_message, preset_name_delete, preset_name_select, preset_flow_delete, select_preset_backup
    else:
        return i18n("é¢„è®¾ä¸å­˜åœ¨")

def run_single_inference_flow(input_audio, store_dir, preset_name, force_cpu, output_format_flow):
    if not input_audio:
        return i18n("è¯·ä¸Šä¼ ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶")
    if os.path.exists(TEMP_PATH):
        shutil.rmtree(TEMP_PATH)
    os.makedirs(TEMP_PATH)
    shutil.copy(input_audio, TEMP_PATH)
    input_folder = TEMP_PATH
    msg = run_inference_flow(input_folder, store_dir, preset_name, force_cpu, output_format_flow, isSingle=True)
    return msg

def run_inference_flow(input_folder, store_dir, preset_name, force_cpu, output_format_flow, isSingle=False):
    global stop_infer_flow
    stop_infer_flow = False
    start_time = time.time()
    preset_data = load_configs(PRESETS)
    if not preset_name in preset_data.keys():
        return i18n("é¢„è®¾") + preset_name + i18n("ä¸å­˜åœ¨")
    config = load_configs(WEBUI_CONFIG)
    config['inference']['preset'] = preset_name
    config['inference']['force_cpu'] = force_cpu
    config['inference']['output_format_flow'] = output_format_flow
    config['inference']['input_folder_flow'] = input_folder
    config['inference']['store_dir_flow'] = store_dir
    save_configs(config, WEBUI_CONFIG)
    model_list = preset_data[preset_name]
    input_to_use = input_folder
    if os.path.exists(TEMP_PATH) and not isSingle:
        shutil.rmtree(TEMP_PATH)
    tmp_store_dir = f"{TEMP_PATH}/inferflow_step1_output"
    for step in model_list.keys():
        model_name = model_list[step]["model_name"]
        if model_name not in load_msst_model() and model_name not in load_vr_model():
            return i18n("æ¨¡å‹") + model_name + i18n("ä¸å­˜åœ¨")
    i = 0
    for step in model_list.keys():
        if stop_infer_flow:
            stop_infer_flow = False
            break
        if i == 0:
            input_to_use = input_folder
        elif i < len(model_list.keys()) - 1 and i > 0:
            if input_to_use != input_folder:
                shutil.rmtree(input_to_use)
            input_to_use = tmp_store_dir
            tmp_store_dir = f"{TEMP_PATH}/inferflow_step{i+1}_output"
        elif i == len(model_list.keys()) - 1:
            input_to_use = tmp_store_dir
            tmp_store_dir = store_dir
        console = Console()
        model_name = model_list[step]["model_name"]
        console.rule(f"[yellow]Step {i+1}: Running inference using {model_name}", style="yellow")
        if model_list[step]["model_type"] == "UVR_VR_Models":
            primary_stem, secondary_stem, _, _ = get_vr_model(model_name)
            stem = model_list[step]["stem"]
            vr_select_model = model_name
            vr_window_size = config['inference']['vr_window_size']
            vr_aggression = config['inference']['vr_aggression']
            vr_output_format = output_format_flow
            vr_use_cpu = force_cpu
            vr_primary_stem_only = True if stem == primary_stem else False
            vr_secondary_stem_only = True if stem == secondary_stem else False
            vr_audio_input = input_to_use
            vr_store_dir = tmp_store_dir
            vr_batch_size = config['inference']['vr_batch_size']
            vr_normalization = config['inference']['vr_normalization']
            vr_post_process_threshold = config['inference']['vr_post_process_threshold']
            vr_invert_spect = config['inference']['vr_invert_spect']
            vr_enable_tta = config['inference']['vr_enable_tta']
            vr_high_end_process = config['inference']['vr_high_end_process']
            vr_enable_post_process = config['inference']['vr_enable_post_process']
            vr_debug_mode = config['inference']['vr_debug_mode']
            try:
                secondary_output = model_list[step]["secondary_output"]
            except KeyError:
                secondary_output = "False"
            if secondary_output == "True":
                save_another_stem = True
                extra_output_dir = os.path.join(store_dir, "secondary_output")
            else:
                save_another_stem = False
                extra_output_dir = None
            vr_inference(vr_select_model, vr_window_size, vr_aggression, vr_output_format, vr_use_cpu, vr_primary_stem_only, vr_secondary_stem_only, vr_audio_input, vr_store_dir, vr_batch_size, vr_normalization, vr_post_process_threshold, vr_invert_spect, vr_enable_tta, vr_high_end_process, vr_enable_post_process, vr_debug_mode, save_another_stem, extra_output_dir)
        else:
            gpu_id = config['inference']['gpu_id'] if not force_cpu else "0"
            use_tta = config['inference']['use_tta']
            try:
                secondary_output = model_list[step]["secondary_output"]
            except KeyError:
                secondary_output = "False"
            if secondary_output == "True":
                extract_instrumental = True
                extra_store_dir = os.path.join(store_dir, "secondary_output")
            else:
                extract_instrumental = False
                extra_store_dir = None
            run_inference(model_name, input_to_use, tmp_store_dir, extract_instrumental, gpu_id, output_format_flow, force_cpu, use_tta, extra_store_dir)
        i += 1
    shutil.rmtree(TEMP_PATH)
    finish_time = time.time()
    elapsed_time = finish_time - start_time
    Console().rule(f"[yellow]Finished runing {preset_name}! Costs {elapsed_time:.2f}s", style="yellow")
    return i18n("å¤„ç†å®Œæˆ! åˆ†ç¦»å®Œæˆçš„éŸ³é¢‘æ–‡ä»¶å·²ä¿å­˜åœ¨") + store_dir

def preset_backup_list():
    backup_dir = BACKUP
    if not os.path.exists(backup_dir):
        return [i18n("æš‚æ— å¤‡ä»½æ–‡ä»¶")]
    backup_files = []
    for file in os.listdir(backup_dir):
        if file.startswith("preset_backup_") and file.endswith(".json"):
            backup_files.append(file)
    if backup_files == []:
        return [i18n("æš‚æ— å¤‡ä»½æ–‡ä»¶")]
    return backup_files

def restore_preset_func(backup_file):
    backup_dir = BACKUP
    if not backup_file or backup_file == i18n("æš‚æ— å¤‡ä»½æ–‡ä»¶"):
        return i18n("è¯·é€‰æ‹©å¤‡ä»½æ–‡ä»¶")
    backup_data = load_configs(os.path.join(backup_dir, backup_file))
    save_configs(backup_data, PRESETS)
    output_message_manage = i18n("å·²æˆåŠŸæ¢å¤å¤‡ä»½") + backup_file
    preset_dropdown = gr.Dropdown(label=i18n("è¯·é€‰æ‹©é¢„è®¾"), choices=list(backup_data.keys()))
    preset_name_delet = gr.Dropdown(label=i18n("è¯·é€‰æ‹©é¢„è®¾"), choices=list(backup_data.keys()))
    preset_flow_delete = pd.DataFrame({"model_type": [i18n("è¯·å…ˆé€‰æ‹©é¢„è®¾")], "model_name": [i18n("è¯·å…ˆé€‰æ‹©é¢„è®¾")], "stem": [i18n("è¯·å…ˆé€‰æ‹©é¢„è®¾")], "secondary_output": [i18n("è¯·å…ˆé€‰æ‹©é¢„è®¾")]})
    return output_message_manage, preset_dropdown, preset_name_delet, preset_flow_delete

def backup_preset_func():
    backup_dir = BACKUP
    if not os.path.exists(backup_dir):
        os.makedirs(backup_dir)
    backup_file = f"preset_backup_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.json"
    preset_data = load_configs(PRESETS)
    save_configs(preset_data, os.path.join(backup_dir, backup_file))
    msg = i18n("å·²æˆåŠŸå¤‡ä»½è‡³") + backup_file
    select_preset_backup = gr.Dropdown(label=i18n("é€‰æ‹©éœ€è¦æ¢å¤çš„é¢„è®¾æµç¨‹å¤‡ä»½"), choices=preset_backup_list(), interactive=True, scale=4)
    return msg, select_preset_backup

def convert_audio(uploaded_files, ffmpeg_output_format, ffmpeg_output_folder):
    if not uploaded_files:
        return i18n("è¯·ä¸Šä¼ è‡³å°‘ä¸€ä¸ªæ–‡ä»¶")
    success_files = []
    for uploaded_file in uploaded_files:
        uploaded_file_path = uploaded_file.name
        output_path = ffmpeg_output_folder
        if not os.path.exists(output_path):
            os.makedirs(output_path)
        config = load_configs(WEBUI_CONFIG)
        config['tools']['ffmpeg_output_format'] = ffmpeg_output_format
        config['tools']['ffmpeg_output_folder'] = ffmpeg_output_folder
        save_configs(config, WEBUI_CONFIG)
        output_file = os.path.join(output_path, os.path.splitext(
            os.path.basename(uploaded_file_path))[0] + "." + ffmpeg_output_format)
        command = f"{FFMPEG} -i \"{uploaded_file_path}\" \"{output_file}\""
        print_command(command)
        try:
            subprocess.run(command, shell=True, check=True)
            success_files.append(output_file)
        except subprocess.CalledProcessError:
            print(f"Fail to convert file: {uploaded_file_path}\n")
            continue
    if not success_files:
        return i18n("æ‰€æœ‰æ–‡ä»¶è½¬æ¢å¤±è´¥, è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œffmpegè·¯å¾„ã€‚")
    else:
        text = i18n("å¤„ç†å®Œæˆ, æ–‡ä»¶å·²ä¿å­˜ä¸º: ") + "\n" + "\n".join(success_files)
        return text

def merge_audios(input_folder, output_folder):
    config = load_configs(WEBUI_CONFIG)
    config['tools']['merge_audio_input'] = input_folder
    config['tools']['merge_audio_output'] = output_folder
    save_configs(config, WEBUI_CONFIG)
    combined_audio = AudioSegment.empty()
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
    output_file = os.path.join(output_folder, "merged_audio.wav")
    for filename in sorted(os.listdir(input_folder)):
        if filename.endswith(('.mp3', '.wav', '.ogg', '.flac')):
            file_path = os.path.join(input_folder, filename)
            audio = AudioSegment.from_file(file_path)
            combined_audio += audio
    try:
        combined_audio.export(output_file, format="wav")
        return i18n("å¤„ç†å®Œæˆ, æ–‡ä»¶å·²ä¿å­˜ä¸º: ") + output_file
    except Exception as e:
        print(e)
        return i18n("å¤„ç†å¤±è´¥!")

def read_and_resample_audio(file_path, target_sr=44100):
    audio, _ = librosa.load(file_path, sr=target_sr, mono=False)
    if audio.ndim == 1:
        audio = np.vstack((audio, audio))
    elif audio.ndim == 2 and audio.shape[0] == 1:
        audio = np.vstack((audio[0], audio[0]))
    return audio

def match_length(ref_audio, est_audio):
    min_length = min(ref_audio.shape[1], est_audio.shape[1])
    ref_audio = ref_audio[:, :min_length]
    est_audio = est_audio[:, :min_length]
    return ref_audio, est_audio

def compute_sdr(reference, estimated):
    sdr, _, _, _ = bss_eval_sources(reference, estimated)
    return sdr

def process_audio(true_path, estimated_path):
    target_sr = 44100
    true_audio = read_and_resample_audio(
        true_path, target_sr)
    estimated_audio = read_and_resample_audio(
        estimated_path, target_sr)
    true_audio, estimated_audio = match_length(true_audio, estimated_audio)
    sdr = compute_sdr(true_audio, estimated_audio)
    print(f"SDR: {sdr}")
    return sdr

def ensemble(files, ensemble_mode, weights, output_path):
    if len(files) < 2:
        return i18n("è¯·ä¸Šä¼ è‡³å°‘2ä¸ªæ–‡ä»¶")
    if len(files) != len(weights.split()):
        return i18n("ä¸Šä¼ çš„æ–‡ä»¶æ•°ç›®ä¸æƒé‡æ•°ç›®ä¸åŒ¹é…")
    else:
        config = load_configs(WEBUI_CONFIG)
        config['tools']['ensemble_type'] = ensemble_mode
        config['tools']['ensemble_output_folder'] = output_path
        save_configs(config, WEBUI_CONFIG)
        files_argument = " ".join(files)
        if not os.path.exists(output_path):
            os.makedirs(output_path)
        output_path = os.path.join(output_path, f"ensemble_{ensemble_mode}.wav")
        command = f"{PYTHON} ensemble.py --files {files_argument} --type {ensemble_mode} --weights {weights} --output {output_path}"
        print_command(command)
        try:
            subprocess.run(command, shell = True)
            return i18n("å¤„ç†å®Œæˆ, æ–‡ä»¶å·²ä¿å­˜ä¸º: ") + output_path
        except Exception as e:
            return i18n("å¤„ç†å¤±è´¥!")

def some_inference(audio_file, bpm, output_dir):
    model = "tools/SOME_weights/model_steps_64000_simplified.ckpt"
    if not os.path.isfile(model):
        return i18n("è¯·å…ˆä¸‹è½½SOMEé¢„å¤„ç†æ¨¡å‹å¹¶æ”¾ç½®åœ¨tools/SOME_weightsæ–‡ä»¶å¤¹ä¸‹! ")
    if not audio_file.endswith('.wav'):
        return i18n("è¯·ä¸Šä¼ wavæ ¼å¼æ–‡ä»¶")
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    config = load_configs(WEBUI_CONFIG)
    config['tools']['some_output_folder'] = output_dir
    save_configs(config, WEBUI_CONFIG)
    tempo = int(bpm)
    file_name = os.path.basename(audio_file)[0:-4]
    midi = os.path.join(output_dir, f"{file_name}.mid")
    command = f"{PYTHON} tools/SOME/infer.py --model {model} --wav \"{audio_file}\" --midi \"{midi}\" --tempo {tempo}"
    print_command(command)
    try:
        subprocess.run(command, shell=True)
        return i18n("å¤„ç†å®Œæˆ, æ–‡ä»¶å·²ä¿å­˜ä¸º: ") + midi
    except Exception as e:
        return i18n("å¤„ç†å¤±è´¥!")

def upgrade_download_model_name(model_type_dropdown):
    if model_type_dropdown == "UVR_VR_Models":
        model_map = load_configs(VR_MODEL)
        return gr.Dropdown(label=i18n("é€‰æ‹©æ¨¡å‹"), choices=[keys for keys in model_map.keys()])
    else:
        model_map = load_configs(MSST_MODEL)
        return gr.Dropdown(label=i18n("é€‰æ‹©æ¨¡å‹"), choices=[model["name"] for model in model_map[model_type_dropdown]])

def download_model(model_type, model_name):
    if model_type not in MODEL_CHOICES:
        return i18n("è¯·é€‰æ‹©æ¨¡å‹ç±»å‹")
    if model_type == "UVR_VR_Models":
        downloaded_model = load_vr_model()
        if model_name in downloaded_model:
            return i18n("æ¨¡å‹") + model_name + i18n("å·²å®‰è£…")
        _, _, model_url, model_path = get_vr_model(model_name)
        os.makedirs(model_path, exist_ok=True)
        return download_file(model_url, os.path.join(model_path, model_name), model_name)
    else:
        presets = load_configs(MSST_MODEL)
        model_mapping = load_msst_model()
        if model_name in model_mapping:
            return i18n("æ¨¡å‹") + model_name + i18n("å·²å®‰è£…")
        if model_type not in presets:
            return i18n("æ¨¡å‹ç±»å‹") + model_type + i18n("ä¸å­˜åœ¨")
        _, _, _, model_url = get_msst_model(model_name)
        model_path = f"pretrain/{model_type}/{model_name}"
        os.makedirs(os.path.dirname(model_path), exist_ok=True)
        return download_file(model_url, model_path, model_name)

def download_file(url, path, model_name):
    try:
        print(i18n("æ¨¡å‹") + model_name + i18n("ä¸‹è½½ä¸­"))
        with requests.get(url, stream=True) as r:
            r.raise_for_status()
            total_size = int(r.headers.get('content-length', 0))
            with open(path, 'wb') as f, tqdm(
                total=total_size, unit='B', unit_scale=True
            ) as progress_bar:
                last_update_time = time.time()
                bytes_written = 0
                for data in r.iter_content(1024):
                    f.write(data)
                    bytes_written += len(data)
                    current_time = time.time()
                    if current_time - last_update_time >= 1:
                        progress_bar.update(bytes_written)
                        bytes_written = 0
                        last_update_time = current_time
                progress_bar.update(bytes_written)
        return i18n("æ¨¡å‹") + model_name + i18n("ä¸‹è½½æˆåŠŸ")
    except Exception as e:
        print(e)
        return i18n("æ¨¡å‹") + model_name + i18n("ä¸‹è½½å¤±è´¥")

def manual_download_model(model_type, model_name):
    if model_type not in MODEL_CHOICES:
        return i18n("è¯·é€‰æ‹©æ¨¡å‹ç±»å‹")
    if model_type == "UVR_VR_Models":
        downloaded_model = load_vr_model()
        if model_name in downloaded_model:
            return i18n("æ¨¡å‹") + model_name + i18n("å·²å®‰è£…")
        _, _, model_url, _ = get_vr_model(model_name)
    else:
        presets = load_configs(MSST_MODEL)
        model_mapping = load_msst_model()
        if model_name in model_mapping:
            return i18n("æ¨¡å‹") + model_name + i18n("å·²å®‰è£…")
        if model_type not in presets:
            return i18n("æ¨¡å‹ç±»å‹") + model_type + i18n("ä¸å­˜åœ¨")
        _, _, _, model_url = get_msst_model(model_name)
    webbrowser.open(model_url)
    return i18n("å·²æ‰“å¼€") + model_name + i18n("çš„ä¸‹è½½é“¾æ¥")

def update_vr_param(is_BV_model, is_VR51_model, model_param):
    balance_value = gr.Number(label="balance_value", value=0.0, minimum=0.0, maximum=0.9, step=0.1, interactive=True, visible=True if is_BV_model else False)
    out_channels = gr.Number(label="Out Channels", value=32, minimum=1, step=1, interactive=True, visible=True if is_VR51_model else False)
    out_channels_lstm = gr.Number(label="Out Channels (LSTM layer)", value=128, minimum=1, step=1, interactive=True, visible=True if is_VR51_model else False)
    upload_param = gr.File(label=i18n("ä¸Šä¼ å‚æ•°æ–‡ä»¶"), type="filepath", interactive=True, visible=True if model_param == i18n("ä¸Šä¼ å‚æ•°") else False)
    return balance_value, out_channels, out_channels_lstm, upload_param

def install_unmsst_model(unmsst_model, unmsst_config, unmodel_class, unmodel_type, unmsst_model_link):
    if not os.path.exists(os.path.join(UNOFFICIAL_MODEL, "unofficial_msst_model.json")):
        os.makedirs(UNOFFICIAL_MODEL, exist_ok=True)
    try:
        model_map = load_configs(os.path.join(UNOFFICIAL_MODEL, "unofficial_msst_model.json"))
    except FileNotFoundError:
        model_map = {"multi_stem_models": [], "single_stem_models": [], "vocal_models": []}
    try:
        if unmsst_model.endswith((".ckpt", ".chpt", ".th")):
            shutil.copy(unmsst_model, os.path.join(MODEL_FOLDER, unmodel_class))
        else: return i18n("è¯·ä¸Šä¼ 'ckpt', 'chpt', 'th'æ ¼å¼çš„æ¨¡å‹æ–‡ä»¶")
        if unmsst_config.endswith(".yaml"):
            shutil.copy(unmsst_config, UNOFFICIAL_MODEL)
        else: return i18n("è¯·ä¸Šä¼ '.yaml'æ ¼å¼çš„é…ç½®æ–‡ä»¶")
        config = {
            "name": os.path.basename(unmsst_model),
            "config_path": os.path.join(UNOFFICIAL_MODEL, os.path.basename(unmsst_config)),
            "model_type": unmodel_type,
            "link": unmsst_model_link
        }
        model_map[unmodel_class].append(config)
        save_configs(model_map, os.path.join(UNOFFICIAL_MODEL, "unofficial_msst_model.json"))
        return i18n("æ¨¡å‹") + os.path.basename(unmsst_model) + i18n("å®‰è£…æˆåŠŸã€‚é‡å¯WebUIä»¥åˆ·æ–°æ¨¡å‹åˆ—è¡¨")
    except Exception as e:
        print(e)
        return i18n("æ¨¡å‹") + os.path.basename(unmsst_model) + i18n("å®‰è£…å¤±è´¥")

def install_unvr_model(unvr_model, unvr_primary_stem, unvr_secondary_stem, model_param, is_karaoke_model, is_BV_model, is_VR51_model, balance_value, out_channels, out_channels_lstm, upload_param, unvr_model_link):
    if not os.path.exists(os.path.join(UNOFFICIAL_MODEL, "unofficial_vr_model.json")):
        os.makedirs(UNOFFICIAL_MODEL, exist_ok=True)
    try:
        model_map = load_configs(os.path.join(UNOFFICIAL_MODEL, "unofficial_vr_model.json"))
    except FileNotFoundError:
        model_map = {}
    try:
        if unvr_model.endswith(".pth"):
            shutil.copy(unvr_model, "pretrain/VR_Models")
        else: return i18n("è¯·ä¸Šä¼ '.pth'æ ¼å¼çš„æ¨¡å‹æ–‡ä»¶")
        if unvr_primary_stem != "" and unvr_secondary_stem != "" and unvr_primary_stem != unvr_secondary_stem:
            model_name = os.path.basename(unvr_model)
            model_map[model_name] = {}
            model_map[model_name]["model_path"] = os.path.join(MODEL_FOLDER, "VR_Models", model_name)
            model_map[model_name]["primary_stem"] = unvr_primary_stem
            model_map[model_name]["secondary_stem"] = unvr_secondary_stem
            model_map[model_name]["download_link"] = unvr_model_link
        else: return i18n("è¯·è¾“å…¥æ­£ç¡®çš„éŸ³è½¨åç§°")
        if model_param == i18n("ä¸Šä¼ å‚æ•°"):
            if upload_param.endswith(".json"):
                shutil.copy(upload_param, "models/vocal_remover/uvr_lib_v5/vr_network/modelparams")
                model_map[model_name]["vr_model_param"] = os.path.basename(upload_param)[:-5]
            else: return i18n("è¯·ä¸Šä¼ '.json'æ ¼å¼çš„å‚æ•°æ–‡ä»¶")
        else: model_map[model_name]["vr_model_param"] = model_param
        if is_karaoke_model:
            model_map[model_name]["is_karaoke"] = True
        if is_BV_model:
            model_map[model_name]["is_bv_model"] = True
            model_map[model_name]["is_bv_model_rebalanced"] = balance_value
        if is_VR51_model:
            model_map[model_name]["nout"] = out_channels
            model_map[model_name]["nout_lstm"] = out_channels_lstm
        save_configs(model_map, os.path.join(UNOFFICIAL_MODEL, "unofficial_vr_model.json"))
        return i18n("æ¨¡å‹") + os.path.basename(unvr_model) + i18n("å®‰è£…æˆåŠŸã€‚é‡å¯WebUIä»¥åˆ·æ–°æ¨¡å‹åˆ—è¡¨")
    except Exception as e:
        print(e)
        return i18n("æ¨¡å‹") + os.path.basename(unvr_model) + i18n("å®‰è£…å¤±è´¥")

def get_all_model_param():
    model_param = [i18n("ä¸Šä¼ å‚æ•°")]
    for file in os.listdir("models/vocal_remover/uvr_lib_v5/vr_network/modelparams"):
        if file.endswith(".json"):
            model_param.append(file[:-5])
    return model_param

def start_training(train_model_type, train_config_path, train_dataset_type, train_dataset_path, train_valid_path, train_num_workers, train_device_ids, train_seed, train_pin_memory, train_use_multistft_loss, train_use_mse_loss, train_use_l1_loss, train_results_path, train_start_check_point, train_accelerate, train_pre_validate):
    model_type = train_model_type
    config_path = train_config_path
    start_check_point = train_start_check_point
    results_path = train_results_path
    data_path = train_dataset_path
    dataset_type = train_dataset_type
    valid_path = train_valid_path
    num_workers = int(train_num_workers)
    device_ids = train_device_ids
    seed = int(train_seed)
    pin_memory = train_pin_memory
    use_multistft_loss = "--use_multistft_loss" if train_use_multistft_loss else ""
    use_mse_loss = "--use_mse_loss" if train_use_mse_loss else ""
    use_l1_loss = "--use_l1_loss" if train_use_l1_loss else ""
    pre_valid = "--pre_valid" if (train_accelerate and train_pre_validate) else ""
    if train_accelerate:
        train_file = "train_accelerate.py"
    else:
        train_file = "train.py"
    if model_type not in MODEL_TYPE:
        return i18n("æ¨¡å‹ç±»å‹é”™è¯¯, è¯·é‡æ–°é€‰æ‹©")
    if not os.path.isfile(config_path):
        return i18n("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨, è¯·é‡æ–°é€‰æ‹©")
    if not os.path.exists(results_path):
        os.makedirs(results_path)
    if not os.path.exists(data_path):
        return i18n("æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨, è¯·é‡æ–°é€‰æ‹©")
    if not os.path.exists(valid_path):
        return i18n("éªŒè¯é›†è·¯å¾„ä¸å­˜åœ¨, è¯·é‡æ–°é€‰æ‹©")
    if dataset_type not in [1, 2, 3, 4]:
        return i18n("æ•°æ®é›†ç±»å‹é”™è¯¯, è¯·é‡æ–°é€‰æ‹©")
    if not bool(re.match(r'^(\d+)(?:\s(?!\1)\d+)*$', device_ids)):
        return i18n("device_idsæ ¼å¼é”™è¯¯, è¯·é‡æ–°è¾“å…¥")
    if train_start_check_point == "None" or train_start_check_point == "":
        start_check_point = ""
    elif os.path.exists(results_path):
        start_check_point = "--start_check_point " + "\"" + os.path.join(results_path, train_start_check_point) + "\""
    else:
        return i18n("æ¨¡å‹ä¿å­˜è·¯å¾„ä¸å­˜åœ¨, è¯·é‡æ–°é€‰æ‹©")
    command = f"{PYTHON} {train_file} --model_type {model_type} --config_path \"{config_path}\" {start_check_point} --results_path \"{results_path}\" --data_path \"{data_path}\" --dataset_type {dataset_type} --valid_path \"{valid_path}\" --num_workers {num_workers} --device_ids {device_ids} --seed {seed} --pin_memory {pin_memory} {use_multistft_loss} {use_mse_loss} {use_l1_loss} {pre_valid}"
    threading.Thread(target=run_command, args=(command,), name="msst_training").start()
    return i18n("è®­ç»ƒå¯åŠ¨æˆåŠŸ! è¯·å‰å¾€æ§åˆ¶å°æŸ¥çœ‹è®­ç»ƒä¿¡æ¯! ")

def validate_model(valid_model_type, valid_config_path, valid_model_path, valid_path, valid_results_path, valid_device_ids, valid_num_workers, valid_extension, valid_pin_memory):
    if valid_model_type not in MODEL_TYPE:
        return i18n("æ¨¡å‹ç±»å‹é”™è¯¯, è¯·é‡æ–°é€‰æ‹©")
    if not os.path.isfile(valid_config_path):
        return i18n("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨, è¯·é‡æ–°é€‰æ‹©")
    if not os.path.isfile(valid_model_path):
        return i18n("æ¨¡å‹ä¸å­˜åœ¨, è¯·é‡æ–°é€‰æ‹©")
    if not os.path.exists(valid_path):
        return i18n("éªŒè¯é›†è·¯å¾„ä¸å­˜åœ¨, è¯·é‡æ–°é€‰æ‹©")
    if not os.path.exists(valid_results_path):
        os.makedirs(valid_results_path)
    if not bool(re.match(r'^(\d+)(?:\s(?!\1)\d+)*$', valid_device_ids)):
        return i18n("device_idsæ ¼å¼é”™è¯¯, è¯·é‡æ–°è¾“å…¥")
    pin_memory = "--pin_memory" if valid_pin_memory else ""
    command = f"{PYTHON} valid.py --model_type {valid_model_type} --config_path \"{valid_config_path}\" --start_check_point \"{valid_model_path}\" --valid_path \"{valid_path}\" --store_dir \"{valid_results_path}\" --device_ids {valid_device_ids} --num_workers {valid_num_workers} --extension {valid_extension} {pin_memory}"
    msst_valid = threading.Thread(target=run_command, args=(command,), name="msst_valid")
    msst_valid.start()
    msst_valid.join()
    return i18n("éªŒè¯å®Œæˆ! è¯·æ‰“å¼€è¾“å‡ºæ–‡ä»¶å¤¹æŸ¥çœ‹è¯¦ç»†ç»“æœ")

def check_webui_update():
    url = "https://github.com/SUC-DriverOld/MSST-WebUI/releases/latest"
    try:
        response = requests.get(url)
        response.raise_for_status()
        latest_version = response.url.split("/")[-1]
        if latest_version != PACKAGE_VERSION:
            return i18n("å½“å‰ç‰ˆæœ¬: ") + PACKAGE_VERSION + i18n(", å‘ç°æ–°ç‰ˆæœ¬: ") + latest_version
        else:
            return i18n("å½“å‰ç‰ˆæœ¬: ") + PACKAGE_VERSION + i18n(", å·²æ˜¯æœ€æ–°ç‰ˆæœ¬")
    except Exception:
        return i18n("æ£€æŸ¥æ›´æ–°å¤±è´¥")

def webui_goto_github():
    webbrowser.open("https://github.com/SUC-DriverOld/MSST-WebUI/releases/latest")

def change_language(language):
    config = load_configs(WEBUI_CONFIG)
    if language in language_dict.keys():
        config['settings']['language'] = language_dict[language]
    else:
        config['settings']['language'] = "Auto"
    save_configs(config, WEBUI_CONFIG)
    return i18n("è¯­è¨€å·²æ›´æ”¹, é‡å¯WebUIç”Ÿæ•ˆ")

def get_language():
    config = load_configs(WEBUI_CONFIG)
    language = config['settings']['language']
    for key, value in language_dict.items():
        if value == language:
            return key
    return "Auto"

def save_port_to_config(port):
    port = int(port)
    config = load_configs(WEBUI_CONFIG)
    config['settings']['port'] = port
    save_configs(config, WEBUI_CONFIG)
    return i18n("æˆåŠŸå°†ç«¯å£è®¾ç½®ä¸º") + str(port) + i18n(", é‡å¯WebUIç”Ÿæ•ˆ")

def change_download_link(link):
    config = load_configs(WEBUI_CONFIG)
    if link == i18n("huggingface.co (éœ€è¦é­”æ³•)"):
        config['settings']['download_link'] = "huggingface.co"
    elif link == i18n("hf-mirror.com (é•œåƒç«™å¯ç›´è¿)"):
        config['settings']['download_link'] = "hf-mirror.com"
    else:
        config['settings']['download_link'] = "Auto"
    save_configs(config, WEBUI_CONFIG)
    return i18n("ä¸‹è½½é“¾æ¥å·²æ›´æ”¹")

def change_share_link(flag):
    config = load_configs(WEBUI_CONFIG)
    if flag:
        config['settings']['share_link'] = True
        save_configs(config, WEBUI_CONFIG)
        return i18n("å…¬å…±é“¾æ¥å·²å¼€å¯, é‡å¯WebUIç”Ÿæ•ˆ")
    else:
        config['settings']['share_link'] = False
        save_configs(config, WEBUI_CONFIG)
        return i18n("å…¬å…±é“¾æ¥å·²å…³é—­, é‡å¯WebUIç”Ÿæ•ˆ")

def change_local_link(flag):
    config = load_configs(WEBUI_CONFIG)
    if flag:
        config['settings']['local_link'] = True
        save_configs(config, WEBUI_CONFIG)
        return i18n("å·²å¼€å¯å±€åŸŸç½‘åˆ†äº«, é‡å¯WebUIç”Ÿæ•ˆ")
    else:
        config['settings']['local_link'] = False
        save_configs(config, WEBUI_CONFIG)
        return i18n("å·²å…³é—­å±€åŸŸç½‘åˆ†äº«, é‡å¯WebUIç”Ÿæ•ˆ")

setup_webui()
with gr.Blocks(
        theme=gr.Theme.load('tools/themes/theme_schema@1.2.2.json')
) as app:
    gr.Markdown(value=f"""### Music-Source-Separation-Training-Inference-Webui v{PACKAGE_VERSION}""")
    gr.Markdown(value=i18n("ä»…ä¾›ä¸ªäººå¨±ä¹å’Œéå•†ä¸šç”¨é€”, ç¦æ­¢ç”¨äºè¡€è…¥/æš´åŠ›/æ€§ç›¸å…³/æ”¿æ²»ç›¸å…³å†…å®¹ã€‚[ç‚¹å‡»å‰å¾€æ•™ç¨‹æ–‡æ¡£](https://r1kc63iz15l.feishu.cn/wiki/JSp3wk7zuinvIXkIqSUcCXY1nKc)<br>æœ¬æ•´åˆåŒ…å®Œå…¨å…è´¹, ä¸¥ç¦ä»¥ä»»ä½•å½¢å¼å€’å–, å¦‚æœä½ ä»ä»»ä½•åœ°æ–¹**ä»˜è´¹**è´­ä¹°äº†æœ¬æ•´åˆåŒ…, è¯·**ç«‹å³é€€æ¬¾**ã€‚<br> æ•´åˆåŒ…ä½œè€…: [bilibili@é˜¿ç‹¸ä¸åƒéš¼èˆ](https://space.bilibili.com/403335715) [Github@KitsuneX07](https://github.com/KitsuneX07) | [Bilibili@Sucial](https://space.bilibili.com/445022409) [Github@SUC-DriverOld](https://github.com/SUC-DriverOld) | Gradioä¸»é¢˜: [Gradio Theme](https://huggingface.co/spaces/NoCrypt/miku)"))
    with gr.Tabs():
        webui_config = load_configs(WEBUI_CONFIG)
        presets = load_configs(PRESETS)
        models = load_configs(MSST_MODEL)
        vr_model = load_configs(VR_MODEL)

        with gr.TabItem(label=i18n("MSSTåˆ†ç¦»")):
            gr.Markdown(value=i18n("MSSTéŸ³é¢‘åˆ†ç¦»åŸé¡¹ç›®åœ°å€: [https://github.com/ZFTurbo/Music-Source-Separation-Training](https://github.com/ZFTurbo/Music-Source-Separation-Training)"))
            with gr.Row():
                select_model_type = gr.Dropdown(label=i18n("é€‰æ‹©æ¨¡å‹ç±»å‹"), choices=["vocal_models", "multi_stem_models", "single_stem_models"], value=webui_config['inference']['model_type'] if webui_config['inference']['model_type'] else None, interactive=True, scale=1)
                selected_model = gr.Dropdown(label=i18n("é€‰æ‹©æ¨¡å‹"),choices=load_selected_model(),value=webui_config['inference']['selected_model'] if webui_config['inference']['selected_model'] else None,interactive=True,scale=4)
            with gr.Row():
                gpu_id = gr.Textbox(label=i18n("é€‰æ‹©ä½¿ç”¨çš„GPU ID, å¤šå¡ç”¨æˆ·è¯·ä½¿ç”¨ç©ºæ ¼åˆ†éš”GPU IDã€‚å¯å‰å¾€è®¾ç½®é¡µé¢æŸ¥çœ‹æ˜¾å¡ä¿¡æ¯ã€‚"),value=webui_config['inference']['gpu_id'] if webui_config['inference']['gpu_id'] else "0",interactive=True)
                output_format = gr.Dropdown(label=i18n("è¾“å‡ºæ ¼å¼"),choices=["wav", "mp3", "flac"],value=webui_config['inference']['output_format'] if webui_config['inference']['output_format'] else "wav", interactive=True)
            with gr.Row():
                force_cpu = gr.Checkbox(label=i18n("ä½¿ç”¨CPU (æ³¨æ„: ä½¿ç”¨CPUä¼šå¯¼è‡´é€Ÿåº¦éå¸¸æ…¢) "),value=webui_config['inference']['force_cpu'] if webui_config['inference']['force_cpu'] else False,interactive=True)
                extract_instrumental = gr.Checkbox(label=i18n("åŒæ—¶è¾“å‡ºæ¬¡çº§éŸ³è½¨"),value=webui_config['inference']['extract_instrumental'] if webui_config['inference']['extract_instrumental'] else False,interactive=True)
                use_tta = gr.Checkbox(label=i18n("ä½¿ç”¨TTA (æµ‹è¯•æ—¶å¢å¼º), å¯èƒ½ä¼šæé«˜è´¨é‡, ä½†é€Ÿåº¦ç¨æ…¢"),value=webui_config['inference']['use_tta'] if webui_config['inference']['use_tta'] else False,interactive=True)
            with gr.Tabs():
                with gr.TabItem(label=i18n("å•ä¸ªéŸ³é¢‘ä¸Šä¼ ")):
                    single_audio = gr.File(label=i18n("å•ä¸ªéŸ³é¢‘ä¸Šä¼ "), type="filepath")
                with gr.TabItem(label=i18n("æ‰¹é‡éŸ³é¢‘ä¸Šä¼ ")):
                    with gr.Row():
                        multiple_audio_input = gr.Textbox(label=i18n("è¾“å…¥ç›®å½•"),value=webui_config['inference']['multiple_audio_input'] if webui_config['inference']['multiple_audio_input'] else "input/",interactive=True,scale=3)
                        select_multi_input_dir = gr.Button(i18n("é€‰æ‹©æ–‡ä»¶å¤¹"), scale=1)
                        open_multi_input_dir = gr.Button(i18n("æ‰“å¼€æ–‡ä»¶å¤¹"), scale=1)
            with gr.Row():
                store_dir = gr.Textbox(label=i18n("è¾“å‡ºç›®å½•"),value=webui_config['inference']['store_dir'] if webui_config['inference']['store_dir'] else "results/",interactive=True,scale=3)
                select_store_btn = gr.Button(i18n("é€‰æ‹©æ–‡ä»¶å¤¹"), scale=1)
                open_store_btn = gr.Button(i18n("æ‰“å¼€æ–‡ä»¶å¤¹"), scale=1)
            with gr.Accordion(i18n("æ¨ç†å‚æ•°è®¾ç½®, ä¸åŒæ¨¡å‹ä¹‹é—´å‚æ•°ç›¸äº’ç‹¬ç«‹ (ä¸€èˆ¬ä¸éœ€è¦åŠ¨) "), open=False):
                gr.Markdown(value=i18n("åªæœ‰åœ¨ç‚¹å‡»ä¿å­˜åæ‰ä¼šç”Ÿæ•ˆã€‚å‚æ•°ç›´æ¥å†™å…¥é…ç½®æ–‡ä»¶, æ— æ³•æ’¤é”€ã€‚å‡å¦‚ä¸çŸ¥é“å¦‚ä½•è®¾ç½®, è¯·ä¿æŒé»˜è®¤å€¼ã€‚<br>è¯·ç‰¢è®°è‡ªå·±ä¿®æ”¹å‰çš„å‚æ•°æ•°å€¼, é˜²æ­¢å‡ºç°é—®é¢˜ä»¥åæ— æ³•æ¢å¤ã€‚è¯·ç¡®ä¿è¾“å…¥æ­£ç¡®çš„å‚æ•°, å¦åˆ™å¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹æ— æ³•æ­£å¸¸è¿è¡Œã€‚<br>å‡å¦‚ä¿®æ”¹åæ— æ³•æ¢å¤, è¯·ç‚¹å‡»``é‡ç½®``æŒ‰é’®, è¿™ä¼šä½¿å¾—é…ç½®æ–‡ä»¶æ¢å¤åˆ°é»˜è®¤å€¼ã€‚"))
                if webui_config['inference']['selected_model']:
                    batch_size_number, dim_t_number, num_overlap_number = init_selected_model()
                else:
                    batch_size_number, dim_t_number, num_overlap_number = i18n("è¯·å…ˆé€‰æ‹©æ¨¡å‹"), i18n("è¯·å…ˆé€‰æ‹©æ¨¡å‹"), i18n("è¯·å…ˆé€‰æ‹©æ¨¡å‹")
                with gr.Row():
                    batch_size = gr.Textbox(label=i18n("batch_size: æ‰¹æ¬¡å¤§å°, ä¸€èˆ¬ä¸éœ€è¦æ”¹"), value=batch_size_number)
                    dim_t = gr.Textbox(label=i18n("dim_t: æ—¶åºç»´åº¦å¤§å°, ä¸€èˆ¬ä¸éœ€è¦æ”¹ (éƒ¨åˆ†æ¨¡å‹æ²¡æœ‰æ­¤å‚æ•°)"), value=dim_t_number)
                    num_overlap = gr.Textbox(label=i18n("num_overlap: çª—å£é‡å é•¿åº¦, æ•°å€¼è¶Šå°é€Ÿåº¦è¶Šå¿«, ä½†ä¼šç‰ºç‰²æ•ˆæœ"), value=num_overlap_number)
                normalize = gr.Checkbox(label=i18n("normalize: æ˜¯å¦å¯¹éŸ³é¢‘è¿›è¡Œå½’ä¸€åŒ–å¤„ç† (éƒ¨åˆ†æ¨¡å‹æ²¡æœ‰æ­¤å‚æ•°)"), value=False, interactive=False)
                reset_config_button = gr.Button(i18n("é‡ç½®é…ç½®"), variant="secondary")
                save_config_button = gr.Button(i18n("ä¿å­˜é…ç½®"), variant="primary")
            with gr.Row():
                inference_single = gr.Button(i18n("å•ä¸ªéŸ³é¢‘åˆ†ç¦»"), variant="primary")
                inference_multiple = gr.Button(i18n("æ‰¹é‡éŸ³é¢‘åˆ†ç¦»"), variant="primary")
            with gr.Row():
                output_message = gr.Textbox(label="Output Message", scale=4)
                stop_thread = gr.Button(i18n("å¼ºåˆ¶åœæ­¢"), scale=1)

            inference_single.click(fn=run_inference_single,inputs=[selected_model, single_audio, store_dir, extract_instrumental, gpu_id, output_format, force_cpu, use_tta],outputs=output_message)
            inference_multiple.click(fn=run_multi_inference, inputs=[selected_model, multiple_audio_input, store_dir, extract_instrumental, gpu_id, output_format, force_cpu, use_tta],outputs=output_message)
            select_model_type.change(fn=update_selected_model, inputs=[select_model_type], outputs=[selected_model])
            selected_model.change(fn=update_inference_settings,inputs=[selected_model],outputs=[batch_size, dim_t, num_overlap, normalize])
            save_config_button.click(fn=save_config,inputs=[selected_model, batch_size, dim_t, num_overlap, normalize],outputs=output_message)
            reset_config_button.click(fn=reset_config,inputs=[selected_model],outputs=output_message)
            select_store_btn.click(fn=select_folder, outputs=store_dir)
            open_store_btn.click(fn=open_folder, inputs=store_dir)
            select_multi_input_dir.click(fn=select_folder, outputs=multiple_audio_input)
            open_multi_input_dir.click(fn=open_folder, inputs=multiple_audio_input)
            stop_thread.click(fn=stop_all_thread)

        with gr.TabItem(label=i18n("UVRåˆ†ç¦»")):
            gr.Markdown(value=i18n("è¯´æ˜: æœ¬æ•´åˆåŒ…ä»…èåˆäº†UVRçš„VR Architectureæ¨¡å‹, MDX23Cå’ŒHtDemucsç±»æ¨¡å‹å¯ä»¥ç›´æ¥ä½¿ç”¨å‰é¢çš„MSSTéŸ³é¢‘åˆ†ç¦»ã€‚<br>UVRåˆ†ç¦»ä½¿ç”¨é¡¹ç›®: [https://github.com/nomadkaraoke/python-audio-separator](https://github.com/nomadkaraoke/python-audio-separator) å¹¶è¿›è¡Œäº†ä¼˜åŒ–ã€‚"))
            vr_select_model = gr.Dropdown(label=i18n("é€‰æ‹©æ¨¡å‹"), choices=load_vr_model(), value=webui_config['inference']['vr_select_model'] if webui_config['inference']['vr_select_model'] else None,interactive=True)
            with gr.Row():
                vr_window_size = gr.Dropdown(label=i18n("Window Size: çª—å£å¤§å°, ç”¨äºå¹³è¡¡é€Ÿåº¦å’Œè´¨é‡"), choices=["320", "512", "1024"], value=webui_config['inference']['vr_window_size'] if webui_config['inference']['vr_window_size'] else "512", interactive=True)
                vr_aggression = gr.Number(label=i18n("Aggression: ä¸»å¹²æå–å¼ºåº¦, èŒƒå›´-100-100, äººå£°è¯·é€‰5"), minimum=-100, maximum=100, value=webui_config['inference']['vr_aggression'] if webui_config['inference']['vr_aggression'] else 5, interactive=True)
                vr_output_format = gr.Dropdown(label=i18n("è¾“å‡ºæ ¼å¼"), choices=["wav", "flac", "mp3"], value=webui_config['inference']['vr_output_format'] if webui_config['inference']['vr_output_format'] else "wav", interactive=True)
            with gr.Row():
                vr_primary_stem_label, vr_secondary_stem_label = init_selected_vr_model()
                vr_use_cpu = gr.Checkbox(label=i18n("ä½¿ç”¨CPU"), value=webui_config['inference']['vr_use_cpu'] if webui_config['inference']['vr_use_cpu'] else False, interactive=True)
                vr_primary_stem_only = gr.Checkbox(label=vr_primary_stem_label, value=webui_config['inference']['vr_primary_stem_only'] if webui_config['inference']['vr_primary_stem_only'] else False, interactive=True)
                vr_secondary_stem_only = gr.Checkbox(label=vr_secondary_stem_label, value=webui_config['inference']['vr_secondary_stem_only'] if webui_config['inference']['vr_secondary_stem_only'] else False, interactive=True)
            with gr.Tabs():
                with gr.TabItem(label=i18n("å•ä¸ªéŸ³é¢‘ä¸Šä¼ ")):
                    vr_single_audio = gr.File(label="å•ä¸ªéŸ³é¢‘ä¸Šä¼ ", type="filepath")
                with gr.TabItem(label=i18n("æ‰¹é‡éŸ³é¢‘ä¸Šä¼ ")):
                    with gr.Row():
                        vr_multiple_audio_input = gr.Textbox(label=i18n("è¾“å…¥ç›®å½•"),value=webui_config['inference']['vr_multiple_audio_input'] if webui_config['inference']['vr_multiple_audio_input'] else "input/", interactive=True, scale=3)
                        vr_select_multi_input_dir = gr.Button(i18n("é€‰æ‹©æ–‡ä»¶å¤¹"), scale=1)
                        vr_open_multi_input_dir = gr.Button(i18n("æ‰“å¼€æ–‡ä»¶å¤¹"), scale=1)
            with gr.Row():
                vr_store_dir = gr.Textbox(label=i18n("è¾“å‡ºç›®å½•"),value=webui_config['inference']['vr_store_dir'] if webui_config['inference']['vr_store_dir'] else "results/",interactive=True,scale=3)
                vr_select_store_btn = gr.Button(i18n("é€‰æ‹©æ–‡ä»¶å¤¹"), scale=1)
                vr_open_store_btn = gr.Button(i18n("æ‰“å¼€æ–‡ä»¶å¤¹"), scale=1)
            with gr.Accordion(i18n("ä»¥ä¸‹æ˜¯ä¸€äº›é«˜çº§è®¾ç½®, ä¸€èˆ¬ä¿æŒé»˜è®¤å³å¯"), open=False):
                with gr.Row():
                    vr_batch_size = gr.Number(label=i18n("Batch Size: ä¸€æ¬¡è¦å¤„ç†çš„æ‰¹æ¬¡æ•°, è¶Šå¤§å ç”¨è¶Šå¤šRAM, å¤„ç†é€Ÿåº¦åŠ å¿«"), minimum=1, value=webui_config['inference']['vr_batch_size'] if webui_config['inference']['vr_batch_size'] else 2, interactive=True)
                    vr_normalization = gr.Number(label=i18n("Normalization: æœ€å¤§å³°å€¼æŒ¯å¹…, ç”¨äºå½’ä¸€åŒ–è¾“å…¥å’Œè¾“å‡ºéŸ³é¢‘ã€‚å–å€¼ä¸º0-1"), minimum=0.0, maximum=1.0, step=0.01, value=webui_config['inference']['vr_normalization'] if webui_config['inference']['vr_normalization'] else 1, interactive=True)
                    vr_post_process_threshold = gr.Number(label=i18n("Post Process Threshold: åå¤„ç†ç‰¹å¾é˜ˆå€¼, å–å€¼ä¸º0.1-0.3"), minimum=0.1, maximum=0.3, step=0.01, value=webui_config['inference']['vr_post_process_threshold'] if webui_config['inference']['vr_post_process_threshold'] else 0.2, interactive=True)
                with gr.Row():
                    vr_invert_spect = gr.Checkbox(label=i18n("Invert Spectrogram: äºŒçº§æ­¥éª¤å°†ä½¿ç”¨é¢‘è°±å›¾è€Œéæ³¢å½¢è¿›è¡Œåè½¬, å¯èƒ½ä¼šæé«˜è´¨é‡, ä½†é€Ÿåº¦ç¨æ…¢"), value=webui_config['inference']['vr_invert_spect'] if webui_config['inference']['vr_invert_spect'] else False, interactive=True)
                    vr_enable_tta = gr.Checkbox(label=i18n("Enable TTA: å¯ç”¨â€œæµ‹è¯•æ—¶å¢å¼ºâ€, å¯èƒ½ä¼šæé«˜è´¨é‡, ä½†é€Ÿåº¦ç¨æ…¢"), value=webui_config['inference']['vr_enable_tta'] if webui_config['inference']['vr_enable_tta'] else False, interactive=True)
                    vr_high_end_process = gr.Checkbox(label=i18n("High End Process: å°†è¾“å‡ºéŸ³é¢‘ç¼ºå¤±çš„é¢‘ç‡èŒƒå›´é•œåƒè¾“å‡º"), value=webui_config['inference']['vr_high_end_process'] if webui_config['inference']['vr_high_end_process'] else False, interactive=True)
                    vr_enable_post_process = gr.Checkbox(label=i18n("Enable Post Process: è¯†åˆ«äººå£°è¾“å‡ºä¸­æ®‹ç•™çš„äººå·¥ç—•è¿¹, å¯æ”¹å–„æŸäº›æ­Œæ›²çš„åˆ†ç¦»æ•ˆæœ"), value=webui_config['inference']['vr_enable_post_process'] if webui_config['inference']['vr_enable_post_process'] else False, interactive=True)
                vr_debug_mode = gr.Checkbox(label=i18n("Debug Mode: å¯ç”¨è°ƒè¯•æ¨¡å¼, å‘å¼€å‘äººå‘˜åé¦ˆæ—¶, è¯·å¼€å¯æ­¤æ¨¡å¼"), value=webui_config['inference']['vr_debug_mode'] if webui_config['inference']['vr_debug_mode'] else False, interactive=True)
            with gr.Row():
                vr_start_single_inference = gr.Button(i18n("å•ä¸ªéŸ³é¢‘åˆ†ç¦»"), variant="primary")
                vr_start_multi_inference = gr.Button(i18n("æ‰¹é‡éŸ³é¢‘åˆ†ç¦»"), variant="primary")
            with gr.Row():
                vr_output_message = gr.Textbox(label="Output Message", scale=4)
                stop_thread = gr.Button(i18n("å¼ºåˆ¶åœæ­¢"), scale=1)

            vr_select_model.change(fn=load_vr_model_stem,inputs=vr_select_model,outputs=[vr_primary_stem_only, vr_secondary_stem_only])
            vr_select_multi_input_dir.click(fn=select_folder, outputs=vr_multiple_audio_input)
            vr_open_multi_input_dir.click(fn=open_folder, inputs=vr_multiple_audio_input)
            vr_select_store_btn.click(fn=select_folder, outputs=vr_store_dir)
            vr_open_store_btn.click(fn=open_folder, inputs=vr_store_dir)
            vr_start_single_inference.click(fn=vr_inference_single,inputs=[vr_select_model, vr_window_size, vr_aggression, vr_output_format, vr_use_cpu, vr_primary_stem_only, vr_secondary_stem_only, vr_single_audio, vr_store_dir, vr_batch_size, vr_normalization, vr_post_process_threshold, vr_invert_spect, vr_enable_tta, vr_high_end_process, vr_enable_post_process, vr_debug_mode],outputs=vr_output_message)
            vr_start_multi_inference.click(fn=vr_inference_multi,inputs=[vr_select_model, vr_window_size, vr_aggression, vr_output_format, vr_use_cpu, vr_primary_stem_only, vr_secondary_stem_only, vr_multiple_audio_input, vr_store_dir, vr_batch_size, vr_normalization, vr_post_process_threshold, vr_invert_spect, vr_enable_tta, vr_high_end_process, vr_enable_post_process, vr_debug_mode],outputs=vr_output_message)
            stop_thread.click(fn=stop_all_thread)

        with gr.TabItem(label=i18n("é¢„è®¾æµç¨‹")):
            gr.Markdown(value=i18n("é¢„è®¾æµç¨‹å…è®¸æŒ‰ç…§é¢„è®¾çš„é¡ºåºè¿è¡Œå¤šä¸ªæ¨¡å‹ã€‚æ¯ä¸€ä¸ªæ¨¡å‹çš„è¾“å‡ºå°†ä½œä¸ºä¸‹ä¸€ä¸ªæ¨¡å‹çš„è¾“å…¥ã€‚"))
            with gr.Tabs():
                with gr.TabItem(label=i18n("ä½¿ç”¨é¢„è®¾")):
                    gr.Markdown(value=i18n("è¯¥æ¨¡å¼ä¸‹çš„UVRæ¨ç†å‚æ•°å°†ç›´æ¥æ²¿ç”¨UVRåˆ†ç¦»é¡µé¢çš„æ¨ç†å‚æ•°, å¦‚éœ€ä¿®æ”¹è¯·å‰å¾€UVRåˆ†ç¦»é¡µé¢ã€‚<br>ä¿®æ”¹å®Œæˆå, è¿˜éœ€è¦ä»»æ„å¤„ç†ä¸€é¦–æ­Œæ‰èƒ½ä¿å­˜å‚æ•°! "))
                    with gr.Row():
                        preset_dropdown = gr.Dropdown(label=i18n("è¯·é€‰æ‹©é¢„è®¾"),choices=list(presets.keys()),value=webui_config['inference']['preset'] if webui_config['inference']['preset'] else None, interactive=True, scale=4)
                        output_format_flow = gr.Dropdown(label=i18n("è¾“å‡ºæ ¼å¼"),choices=["wav", "mp3", "flac"],value=webui_config['inference']['output_format_flow'] if webui_config['inference']['output_format_flow'] else "wav", interactive=True, scale=1)
                    force_cpu = gr.Checkbox(label=i18n("ä½¿ç”¨CPU (æ³¨æ„: ä½¿ç”¨CPUä¼šå¯¼è‡´é€Ÿåº¦éå¸¸æ…¢) "),value=webui_config['inference']['force_cpu'] if webui_config['inference']['force_cpu'] else False,interactive=True)
                    with gr.Tabs():
                        with gr.TabItem(label=i18n("å•ä¸ªéŸ³é¢‘ä¸Šä¼ ")):
                            single_audio_flow = gr.File(label=i18n("å•ä¸ªéŸ³é¢‘ä¸Šä¼ "), type="filepath")
                        with gr.TabItem(label=i18n("æ‰¹é‡éŸ³é¢‘ä¸Šä¼ ")):
                            with gr.Row():
                                input_folder_flow = gr.Textbox(label=i18n("è¾“å…¥ç›®å½•"),value=webui_config['inference']['input_folder_flow'] if webui_config['inference']['input_folder_flow'] else "input/",interactive=True,scale=3)
                                select_input_dir = gr.Button(i18n("é€‰æ‹©æ–‡ä»¶å¤¹"), scale=1)
                                open_input_dir = gr.Button(i18n("æ‰“å¼€æ–‡ä»¶å¤¹"), scale=1)
                    with gr.Row():
                        store_dir_flow = gr.Textbox(label=i18n("è¾“å‡ºç›®å½•"),value=webui_config['inference']['store_dir_flow'] if webui_config['inference']['store_dir_flow'] else "results/",interactive=True,scale=3)
                        select_output_dir = gr.Button(i18n("é€‰æ‹©æ–‡ä»¶å¤¹"), scale=1)
                        open_output_dir = gr.Button(i18n("æ‰“å¼€æ–‡ä»¶å¤¹"), scale=1)
                    with gr.Row():
                        single_inference_flow = gr.Button(i18n("å•ä¸ªéŸ³é¢‘åˆ†ç¦»"), variant="primary")
                        inference_flow = gr.Button(i18n("æ‰¹é‡éŸ³é¢‘åˆ†ç¦»"), variant="primary")
                    with gr.Row():
                        output_message_flow = gr.Textbox(label="Output Message", scale=4)
                        stop_thread = gr.Button(i18n("å¼ºåˆ¶åœæ­¢"), scale=1)
                with gr.TabItem(label=i18n("åˆ¶ä½œé¢„è®¾")):
                    gr.Markdown(i18n("æ³¨æ„: MSSTæ¨¡å‹ä»…æ”¯æŒè¾“å‡ºä¸»è¦éŸ³è½¨, UVRæ¨¡å‹æ”¯æŒè‡ªå®šä¹‰ä¸»è¦éŸ³è½¨è¾“å‡ºã€‚<br>åŒæ—¶è¾“å‡ºæ¬¡çº§éŸ³è½¨: é€‰æ‹©Trueå°†åŒæ—¶è¾“å‡ºè¯¥æ¬¡åˆ†ç¦»å¾—åˆ°çš„æ¬¡çº§éŸ³è½¨, **æ­¤éŸ³è½¨å°†ç›´æ¥ä¿å­˜è‡³**è¾“å‡ºç›®å½•ä¸‹çš„secondary_outputæ–‡ä»¶å¤¹, **ä¸ä¼šç»è¿‡åç»­æµç¨‹å¤„ç†**<br>"))
                    preset_name_input = gr.Textbox(label=i18n("é¢„è®¾åç§°"), placeholder=i18n("è¯·è¾“å…¥é¢„è®¾åç§°"), interactive=True)
                    with gr.Row():
                        model_type = gr.Dropdown(label=i18n("é€‰æ‹©æ¨¡å‹ç±»å‹"), choices=MODEL_CHOICES, interactive=True)
                        model_name = gr.Dropdown(label=i18n("é€‰æ‹©æ¨¡å‹"), choices=[i18n("è¯·å…ˆé€‰æ‹©æ¨¡å‹ç±»å‹")], interactive=True, scale=2)
                        stem = gr.Dropdown(label=i18n("è¾“å‡ºéŸ³è½¨"), choices=[i18n("è¯·å…ˆé€‰æ‹©æ¨¡å‹")], interactive=True)
                        secondary_output = gr.Dropdown(label=i18n("åŒæ—¶è¾“å‡ºæ¬¡çº§éŸ³è½¨"), choices=["True", "False"], value="False", interactive=True)
                    add_to_flow = gr.Button(i18n("æ·»åŠ è‡³æµç¨‹"))
                    gr.Markdown(i18n("é¢„è®¾æµç¨‹"))
                    preset_flow = gr.Dataframe(pd.DataFrame({"model_type": [""], "model_name": [""], "stem": [""], "secondary_output": [""]}), interactive=False, label=None)
                    reset_flow = gr.Button(i18n("é‡æ–°è¾“å…¥"))
                    save_flow = gr.Button(i18n("ä¿å­˜ä¸Šè¿°é¢„è®¾æµç¨‹"), variant="primary")
                    output_message_make = gr.Textbox(label="Output Message")
                with gr.TabItem(label=i18n("ç®¡ç†é¢„è®¾")):
                    gr.Markdown(i18n("æ­¤é¡µé¢æä¾›æŸ¥çœ‹é¢„è®¾, åˆ é™¤é¢„è®¾, å¤‡ä»½é¢„è®¾, æ¢å¤é¢„è®¾ç­‰åŠŸèƒ½"))
                    preset_name_delete = gr.Dropdown(label=i18n("è¯·é€‰æ‹©é¢„è®¾"), choices=list(presets.keys()), interactive=True)
                    gr.Markdown(i18n("`model_type`: æ¨¡å‹ç±»å‹ï¼›`model_name`: æ¨¡å‹åç§°ï¼›`stem`: ä¸»è¦è¾“å‡ºéŸ³è½¨ï¼›<br>`secondary_output`: åŒæ—¶è¾“å‡ºæ¬¡çº§éŸ³è½¨ã€‚é€‰æ‹©Trueå°†åŒæ—¶è¾“å‡ºè¯¥æ¬¡åˆ†ç¦»å¾—åˆ°çš„æ¬¡çº§éŸ³è½¨, **æ­¤éŸ³è½¨å°†ç›´æ¥ä¿å­˜è‡³**è¾“å‡ºç›®å½•ä¸‹çš„secondary_outputæ–‡ä»¶å¤¹, **ä¸ä¼šç»è¿‡åç»­æµç¨‹å¤„ç†**"))
                    preset_flow_delete = gr.Dataframe(pd.DataFrame({"model_type": [i18n("è¯·å…ˆé€‰æ‹©é¢„è®¾")], "model_name": [i18n("è¯·å…ˆé€‰æ‹©é¢„è®¾")], "stem": [i18n("è¯·å…ˆé€‰æ‹©é¢„è®¾")], "secondary_output": [i18n("è¯·å…ˆé€‰æ‹©é¢„è®¾")]}), interactive=False, label=None)
                    delete_button = gr.Button(i18n("åˆ é™¤æ‰€é€‰é¢„è®¾"), scale=1)
                    gr.Markdown(i18n("æ¯æ¬¡åˆ é™¤é¢„è®¾å‰, å°†è‡ªåŠ¨å¤‡ä»½é¢„è®¾ä»¥å…è¯¯æ“ä½œã€‚<br>ä½ ä¹Ÿå¯ä»¥ç‚¹å‡»â€œå¤‡ä»½é¢„è®¾æµç¨‹â€æŒ‰é’®è¿›è¡Œæ‰‹åŠ¨å¤‡ä»½, ä¹Ÿå¯ä»¥ä»å¤‡ä»½æ–‡ä»¶å¤¹ä¸­æ¢å¤é¢„è®¾æµç¨‹ã€‚"))
                    with gr.Row():
                        backup_preset = gr.Button(i18n("å¤‡ä»½é¢„è®¾æµç¨‹"))
                        open_preset_backup = gr.Button(i18n("æ‰“å¼€å¤‡ä»½æ–‡ä»¶å¤¹"))
                    with gr.Row():
                        select_preset_backup = gr.Dropdown(label=i18n("é€‰æ‹©éœ€è¦æ¢å¤çš„é¢„è®¾æµç¨‹å¤‡ä»½"),choices=preset_backup_list(),interactive=True,scale=4)
                        restore_preset = gr.Button(i18n("æ¢å¤"), scale=1)
                    output_message_manage = gr.Textbox(label="Output Message")
                

            inference_flow.click(fn=run_inference_flow,inputs=[input_folder_flow, store_dir_flow, preset_dropdown, force_cpu, output_format_flow],outputs=output_message_flow)
            single_inference_flow.click(fn=run_single_inference_flow,inputs=[single_audio_flow, store_dir_flow, preset_dropdown, force_cpu, output_format_flow],outputs=output_message_flow)
            select_input_dir.click(fn=select_folder, outputs=input_folder_flow)
            open_input_dir.click(fn=open_folder, inputs=input_folder_flow)
            select_output_dir.click(fn=select_folder, outputs=store_dir_flow)
            open_output_dir.click(fn=open_folder, inputs=store_dir_flow)
            model_type.change(update_model_name, inputs=model_type, outputs=model_name)
            model_name.change(update_model_stem, inputs=[model_type, model_name], outputs=stem)
            add_to_flow.click(add_to_flow_func, [model_type, model_name, stem, secondary_output, preset_flow], preset_flow)
            save_flow.click(save_flow_func, [preset_name_input, preset_flow], [output_message_make, preset_name_delete, preset_dropdown])
            reset_flow.click(reset_flow_func, [], preset_flow)
            delete_button.click(delete_func, [preset_name_delete], [output_message_manage, preset_name_delete, preset_dropdown, preset_flow_delete, select_preset_backup])
            preset_name_delete.change(load_preset, inputs=preset_name_delete, outputs=preset_flow_delete)
            stop_thread.click(fn=stop_all_thread)
            restore_preset.click(fn=restore_preset_func,inputs=[select_preset_backup],outputs=[output_message_manage, preset_dropdown, preset_name_delete, preset_flow_delete])
            backup_preset.click(fn=backup_preset_func,outputs=[output_message_manage, select_preset_backup])
            open_preset_backup.click(open_folder, inputs=gr.Textbox(BACKUP, visible=False))

        with gr.TabItem(label=i18n("å°å·¥å…·")):
            with gr.Tabs():
                with gr.TabItem(label=i18n("éŸ³é¢‘æ ¼å¼è½¬æ¢")):
                    gr.Markdown(value=i18n("ä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ªéŸ³é¢‘æ–‡ä»¶å¹¶å°†å…¶è½¬æ¢ä¸ºæŒ‡å®šæ ¼å¼ã€‚<br>æ”¯æŒçš„æ ¼å¼åŒ…æ‹¬ .mp3, .flac, .wav, .ogg, .m4a, .wma, .aac...ç­‰ç­‰ã€‚<br>**ä¸æ”¯æŒ**ç½‘æ˜“äº‘éŸ³ä¹/QQéŸ³ä¹ç­‰åŠ å¯†æ ¼å¼, å¦‚.ncm, .qmcç­‰ã€‚"))
                    with gr.Row():
                        inputs = gr.Files(label=i18n("ä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ªéŸ³é¢‘æ–‡ä»¶"))
                        with gr.Column():
                            ffmpeg_output_format = gr.Dropdown(label=i18n("é€‰æ‹©æˆ–è¾“å…¥éŸ³é¢‘è¾“å‡ºæ ¼å¼"),choices=["wav", "flac", "mp3", "ogg", "m4a", "wma", "aac"],value=webui_config['tools']['ffmpeg_output_format'] if webui_config['tools']['ffmpeg_output_format'] else "wav",allow_custom_value=True,interactive=True)
                            ffmpeg_output_folder = gr.Textbox(label=i18n("é€‰æ‹©éŸ³é¢‘è¾“å‡ºç›®å½•"), value=webui_config['tools']['ffmpeg_output_folder'] if webui_config['tools']['ffmpeg_output_folder'] else "results/ffmpeg_output/", interactive=True)
                            with gr.Row():
                                select_ffmpeg_output_dir = gr.Button(i18n("é€‰æ‹©æ–‡ä»¶å¤¹"))
                                open_ffmpeg_output_dir = gr.Button(i18n("æ‰“å¼€æ–‡ä»¶å¤¹"))
                    convert_audio_button = gr.Button(i18n("è½¬æ¢éŸ³é¢‘"), variant="primary")
                    output_message_ffmpeg = gr.Textbox(label="Output Message")
                with gr.TabItem(label=i18n("åˆå¹¶éŸ³é¢‘")):
                    gr.Markdown(value=i18n("ç‚¹å‡»åˆå¹¶éŸ³é¢‘æŒ‰é’®å, å°†è‡ªåŠ¨æŠŠè¾“å…¥æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶åˆå¹¶ä¸ºä¸€æ•´ä¸ªéŸ³é¢‘æ–‡ä»¶<br>ç›®å‰æ”¯æŒçš„æ ¼å¼åŒ…æ‹¬ .mp3, .flac, .wav, .ogg è¿™å››ç§<br>åˆå¹¶åçš„éŸ³é¢‘ä¼šä¿å­˜è‡³è¾“å‡ºç›®å½•ä¸­, æ–‡ä»¶åä¸ºmerged_audio.wav"))
                    with gr.Row():
                        merge_audio_input = gr.Textbox(label=i18n("è¾“å…¥ç›®å½•"),value=webui_config['tools']['merge_audio_input'] if webui_config['tools']['merge_audio_input'] else "input/",interactive=True,scale=3)
                        select_merge_input_dir = gr.Button(i18n("é€‰æ‹©æ–‡ä»¶å¤¹"), scale=1)
                        open_merge_input_dir = gr.Button(i18n("æ‰“å¼€æ–‡ä»¶å¤¹"), scale=1)
                    with gr.Row():
                        merge_audio_output = gr.Textbox(label=i18n("è¾“å‡ºç›®å½•"),value=webui_config['tools']['merge_audio_output'] if webui_config['tools']['merge_audio_output'] else "results/merge",interactive=True,scale=3)
                        select_merge_output_dir = gr.Button(i18n("é€‰æ‹©æ–‡ä»¶å¤¹"), scale=1)
                        open_merge_output_dir = gr.Button(i18n("æ‰“å¼€æ–‡ä»¶å¤¹"), scale=1)
                    merge_audio_button = gr.Button(i18n("åˆå¹¶éŸ³é¢‘"), variant="primary")
                    output_message_merge = gr.Textbox(label="Output Message")
                with gr.TabItem(label=i18n("è®¡ç®—SDR")):
                    with gr.Column():
                        gr.Markdown(value=i18n("ä¸Šä¼ ä¸¤ä¸ª**wavéŸ³é¢‘æ–‡ä»¶**å¹¶è®¡ç®—å®ƒä»¬çš„[SDR](https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021#evaluation-metric)ã€‚<br>SDRæ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°æ¨¡å‹è´¨é‡çš„æ•°å€¼ã€‚æ•°å€¼è¶Šå¤§, æ¨¡å‹ç®—æ³•ç»“æœè¶Šå¥½ã€‚"))
                    with gr.Row():
                        true_audio = gr.File(label=i18n("åŸå§‹éŸ³é¢‘"), type="filepath")
                        estimated_audio = gr.File(label=i18n("åˆ†ç¦»åçš„éŸ³é¢‘"), type="filepath")
                    compute_sdr_button = gr.Button(i18n("è®¡ç®—SDR"), variant="primary")
                    output_message_sdr = gr.Textbox(label="Output Message")
                with gr.TabItem(label = i18n("Ensembleæ¨¡å¼")):
                    gr.Markdown(value = i18n("å¯ç”¨äºé›†æˆä¸åŒç®—æ³•çš„ç»“æœã€‚å…·ä½“çš„æ–‡æ¡£ä½äº/docs/ensemble.md"))
                    with gr.Row():
                        files = gr.Files(label = i18n("ä¸Šä¼ å¤šä¸ªéŸ³é¢‘æ–‡ä»¶"), type = "filepath", file_count = 'multiple')
                        with gr.Column():
                            with gr.Row():
                                ensemble_type = gr.Dropdown(choices = ["avg_wave", "median_wave", "min_wave", "max_wave", "avg_fft", "median_fft", "min_fft", "max_fft"],label = i18n("é›†æˆæ¨¡å¼"),value = webui_config['tools']['ensemble_type'] if webui_config['tools']['ensemble_type'] else "avg_wave",interactive=True)
                                weights = gr.Textbox(label = i18n("æƒé‡(ä»¥ç©ºæ ¼åˆ†éš”, æ•°é‡è¦ä¸ä¸Šä¼ çš„éŸ³é¢‘ä¸€è‡´)"), value = "1 1")
                            ensembl_output_path = gr.Textbox(label = i18n("è¾“å‡ºç›®å½•"), value = webui_config['tools']['ensemble_output_folder'] if webui_config['tools']['ensemble_output_folder'] else "results/ensemble/",interactive=True)
                            with gr.Row():
                                select_ensembl_output_path = gr.Button(i18n("é€‰æ‹©æ–‡ä»¶å¤¹"))
                                open_ensembl_output_path = gr.Button(i18n("æ‰“å¼€æ–‡ä»¶å¤¹"))
                    ensemble_button = gr.Button(i18n("è¿è¡Œ"), variant = "primary")
                    output_message_ensemble = gr.Textbox(label = "Output Message")
                    with gr.Row():
                        with gr.Column():
                            gr.Markdown(i18n("### é›†æˆæ¨¡å¼"))
                            gr.Markdown(i18n("1. `avg_wave`: åœ¨1Då˜ä½“ä¸Šè¿›è¡Œé›†æˆ, ç‹¬ç«‹åœ°æ‰¾åˆ°æ³¢å½¢çš„æ¯ä¸ªæ ·æœ¬çš„å¹³å‡å€¼<br>2. `median_wave`: åœ¨1Då˜ä½“ä¸Šè¿›è¡Œé›†æˆ, ç‹¬ç«‹åœ°æ‰¾åˆ°æ³¢å½¢çš„æ¯ä¸ªæ ·æœ¬çš„ä¸­ä½æ•°<br>3. `min_wave`: åœ¨1Då˜ä½“ä¸Šè¿›è¡Œé›†æˆ, ç‹¬ç«‹åœ°æ‰¾åˆ°æ³¢å½¢çš„æ¯ä¸ªæ ·æœ¬çš„æœ€å°ç»å¯¹å€¼<br>4. `max_wave`: åœ¨1Då˜ä½“ä¸Šè¿›è¡Œé›†æˆ, ç‹¬ç«‹åœ°æ‰¾åˆ°æ³¢å½¢çš„æ¯ä¸ªæ ·æœ¬çš„æœ€å¤§ç»å¯¹å€¼<br>5. `avg_fft`: åœ¨é¢‘è°±å›¾ (çŸ­æ—¶å‚…é‡Œå¶å˜æ¢ (STFT) 2Då˜ä½“) ä¸Šè¿›è¡Œé›†æˆ, ç‹¬ç«‹åœ°æ‰¾åˆ°é¢‘è°±å›¾çš„æ¯ä¸ªåƒç´ çš„å¹³å‡å€¼ã€‚å¹³å‡åä½¿ç”¨é€†STFTå¾—åˆ°åŸå§‹çš„1Dæ³¢å½¢<br>6. `median_fft`: ä¸avg_fftç›¸åŒ, ä½†ä½¿ç”¨ä¸­ä½æ•°ä»£æ›¿å¹³å‡å€¼ (ä»…åœ¨é›†æˆ3ä¸ªæˆ–æ›´å¤šæ¥æºæ—¶æœ‰ç”¨) <br>7. `min_fft`: ä¸avg_fftç›¸åŒ, ä½†ä½¿ç”¨æœ€å°å‡½æ•°ä»£æ›¿å¹³å‡å€¼ (å‡å°‘æ¿€è¿›ç¨‹åº¦) <br>8. `max_fft`: ä¸avg_fftç›¸åŒ, ä½†ä½¿ç”¨æœ€å¤§å‡½æ•°ä»£æ›¿å¹³å‡å€¼ (å¢åŠ æ¿€è¿›ç¨‹åº¦) "))
                        with gr.Column():
                            gr.Markdown(i18n("### æ³¨æ„äº‹é¡¹"))
                            gr.Markdown(i18n("1. min_fftå¯ç”¨äºè¿›è¡Œæ›´ä¿å®ˆçš„åˆæˆ, å®ƒå°†å‡å°‘æ›´æ¿€è¿›æ¨¡å‹çš„å½±å“ã€‚<br>2. æœ€å¥½åˆæˆç­‰è´¨é‡çš„æ¨¡å‹ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹, å®ƒå°†å¸¦æ¥å¢ç›Šã€‚å¦‚æœå…¶ä¸­ä¸€ä¸ªæ¨¡å‹è´¨é‡ä¸å¥½, å®ƒå°†é™ä½æ•´ä½“è´¨é‡ã€‚<br>3. åœ¨åŸä»“åº“ä½œè€…çš„å®éªŒä¸­, ä¸å…¶ä»–æ–¹æ³•ç›¸æ¯”, avg_waveåœ¨SDRåˆ†æ•°ä¸Šæ€»æ˜¯æ›´å¥½æˆ–ç›¸ç­‰ã€‚<br>4. ä¸Šä¼ çš„æ–‡ä»¶å**ä¸èƒ½åŒ…å«ç©ºæ ¼**, æœ€ç»ˆä¼šåœ¨è¾“å‡ºç›®å½•ä¸‹ç”Ÿæˆä¸€ä¸ª`ensemble_<é›†æˆæ¨¡å¼>.wav`ã€‚"))
                with gr.TabItem(label=i18n("æ­Œå£°è½¬MIDI")):
                    gr.Markdown(value=i18n("æ­Œå£°è½¬MIDIåŠŸèƒ½ä½¿ç”¨å¼€æºé¡¹ç›®[SOME](https://github.com/openvpi/SOME/), å¯ä»¥å°†åˆ†ç¦»å¾—åˆ°çš„**å¹²å‡€çš„æ­Œå£°**è½¬æ¢æˆ.midæ–‡ä»¶ã€‚<br>ã€å¿…é¡»ã€‘è‹¥æƒ³è¦ä½¿ç”¨æ­¤åŠŸèƒ½, è¯·å…ˆä¸‹è½½æƒé‡æ–‡ä»¶[model_steps_64000_simplified.ckpt](https://hf-mirror.com/Sucial/SOME_Models/resolve/main/model_steps_64000_simplified.ckpt)å¹¶å°†å…¶æ”¾ç½®åœ¨ç¨‹åºç›®å½•ä¸‹çš„`tools/SOME_weights`æ–‡ä»¶å¤¹å†…ã€‚æ–‡ä»¶å‘½åä¸å¯éšæ„æ›´æ”¹! <br>ã€é‡è¦ã€‘åªèƒ½ä¸Šä¼ wavæ ¼å¼çš„éŸ³é¢‘! "))
                    with gr.Row():
                        some_input_audio = gr.File(label=i18n("ä¸Šä¼ wavæ ¼å¼éŸ³é¢‘"), type="filepath")
                        with gr.Column():
                            audio_bpm = gr.Number(label=i18n("è¾“å…¥éŸ³é¢‘BPM"), value=120, interactive=True)
                            some_output_folder = gr.Textbox(label=i18n("è¾“å‡ºç›®å½•"),value=webui_config['tools']['some_output_folder'] if webui_config['tools']['some_output_folder'] else "results/some/",interactive=True,scale=3)
                            with gr.Row():
                                select_some_output_dir = gr.Button(i18n("é€‰æ‹©æ–‡ä»¶å¤¹"))
                                open_some_output_dir = gr.Button(i18n("æ‰“å¼€æ–‡ä»¶å¤¹"))
                    some_button = gr.Button(i18n("å¼€å§‹è½¬æ¢"), variant="primary")
                    output_message_some = gr.Textbox(label="Output Message")
                    gr.Markdown(i18n("### æ³¨æ„äº‹é¡¹"))
                    gr.Markdown(i18n("1. éŸ³é¢‘BPM (æ¯åˆ†é’ŸèŠ‚æ‹æ•°) å¯ä»¥é€šè¿‡MixMeister BPM Analyzerç­‰è½¯ä»¶æµ‹é‡è·å–ã€‚<br>2. ä¸ºä¿è¯MIDIæå–è´¨é‡, éŸ³é¢‘æ–‡ä»¶è¯·é‡‡ç”¨å¹²å‡€æ¸…æ™°æ— æ··å“åº•å™ªäººå£°ã€‚<br>3. è¾“å‡ºMIDIä¸å¸¦æ­Œè¯ä¿¡æ¯, éœ€è¦ç”¨æˆ·è‡ªè¡Œæ·»åŠ æ­Œè¯ã€‚<br>4. å®é™…ä½¿ç”¨ä½“éªŒä¸­éƒ¨åˆ†éŸ³ç¬¦ä¼šå‡ºç°æ–­å¼€çš„ç°è±¡, éœ€è‡ªè¡Œä¿®æ­£ã€‚SOMEçš„æ¨¡å‹ä¸»è¦é¢å‘DiffSingerå”±æ³•æ¨¡å‹è‡ªåŠ¨æ ‡æ³¨, æ¯”æ­£å¸¸ç”¨æˆ·åœ¨åˆ›ä½œä¸­éœ€è¦çš„MIDIæ›´åŠ ç²¾ç»†, å› è€Œå¯èƒ½å¯¼è‡´æ¨¡å‹å€¾å‘äºå¯¹éŸ³ç¬¦è¿›è¡Œåˆ‡åˆ†ã€‚<br>5. æå–çš„MIDIæ²¡æœ‰é‡åŒ–/æ²¡æœ‰å¯¹é½èŠ‚æ‹/ä¸é€‚é…BPM, éœ€è‡ªè¡Œåˆ°å„ç¼–è¾‘å™¨ä¸­æ‰‹åŠ¨è°ƒæ•´ã€‚"))

            convert_audio_button.click(fn=convert_audio, inputs=[inputs, ffmpeg_output_format, ffmpeg_output_folder], outputs=output_message_ffmpeg)
            select_ffmpeg_output_dir.click(fn=select_folder, outputs=ffmpeg_output_folder)
            open_ffmpeg_output_dir.click(fn=open_folder, inputs=ffmpeg_output_folder)
            merge_audio_button.click(merge_audios, [merge_audio_input, merge_audio_output], outputs=output_message_merge)
            select_merge_input_dir.click(fn=select_folder, outputs=merge_audio_input)
            open_merge_input_dir.click(fn=open_folder, inputs=merge_audio_input)
            select_merge_output_dir.click(fn=select_folder, outputs=merge_audio_output)
            open_merge_output_dir.click(fn=open_folder, inputs=merge_audio_output)
            compute_sdr_button.click(process_audio, [true_audio, estimated_audio], outputs=output_message_sdr)
            ensemble_button.click(fn = ensemble, inputs = [files, ensemble_type, weights, ensembl_output_path],outputs = output_message_ensemble)
            select_ensembl_output_path.click(fn = select_folder, outputs = ensembl_output_path)
            open_ensembl_output_path.click(fn = open_folder, inputs = ensembl_output_path)
            select_some_output_dir.click(fn=select_folder, outputs=some_output_folder)
            open_some_output_dir.click(fn=open_folder, inputs=some_output_folder)
            some_button.click(fn=some_inference,inputs=[some_input_audio, audio_bpm, some_output_folder],outputs=output_message_some)

        with gr.TabItem(label=i18n("å®‰è£…æ¨¡å‹")):
            with gr.Tabs():
                with gr.TabItem(label=i18n("ä¸‹è½½å®˜æ–¹æ¨¡å‹")):
                    uvr_model_folder = webui_config['settings']['uvr_model_dir']
                    gr.Markdown(value=i18n("è‹¥è‡ªåŠ¨ä¸‹è½½å‡ºç°æŠ¥é”™æˆ–ä¸‹è½½è¿‡æ…¢, è¯·ç‚¹å‡»æ‰‹åŠ¨ä¸‹è½½, è·³è½¬è‡³ä¸‹è½½é“¾æ¥ã€‚æ‰‹åŠ¨ä¸‹è½½å®Œæˆå, è¯·æ ¹æ®ä½ é€‰æ‹©çš„æ¨¡å‹ç±»å‹æ”¾ç½®åˆ°å¯¹åº”æ–‡ä»¶å¤¹å†…ã€‚"))
                    gr.Markdown(value=i18n("### å½“å‰UVRæ¨¡å‹ç›®å½•: ") + f"`{uvr_model_folder}`" + i18n(", å¦‚éœ€æ›´æ”¹, è¯·å‰å¾€è®¾ç½®é¡µé¢ã€‚"))
                    with gr.Row():
                        with gr.Column(scale=3):
                            with gr.Row():
                                model_type_dropdown = gr.Dropdown(label=i18n("é€‰æ‹©æ¨¡å‹ç±»å‹"), choices=MODEL_CHOICES, scale=1)
                                download_model_name_dropdown = gr.Dropdown(label=i18n("é€‰æ‹©æ¨¡å‹"), choices=[i18n("è¯·å…ˆé€‰æ‹©æ¨¡å‹ç±»å‹")], scale=3)
                            with gr.Row():
                                open_model_dir = gr.Button(i18n("æ‰“å¼€MSSTæ¨¡å‹ç›®å½•"))
                                open_uvr_model_dir = gr.Button(i18n("æ‰“å¼€UVRæ¨¡å‹ç›®å½•"))
                            with gr.Row():
                                download_button = gr.Button(i18n("è‡ªåŠ¨ä¸‹è½½"), variant="primary")
                                manual_download_button = gr.Button(i18n("æ‰‹åŠ¨ä¸‹è½½"), variant="primary")
                            output_message_download = gr.Textbox(label="Output Message")
                            restart_webui = gr.Button(i18n("é‡å¯WebUI"), variant="primary")
                        with gr.Column(scale=1):
                            gr.Markdown(i18n("### æ³¨æ„äº‹é¡¹"))
                            gr.Markdown(value=i18n("1. MSSTæ¨¡å‹é»˜è®¤ä¸‹è½½åœ¨pretrain/<æ¨¡å‹ç±»å‹>æ–‡ä»¶å¤¹ä¸‹ã€‚UVRæ¨¡å‹é»˜è®¤ä¸‹è½½åœ¨è®¾ç½®ä¸­çš„UVRæ¨¡å‹ç›®å½•ä¸­ã€‚<br>2. ä¸‹åŠ è½½è¿›åº¦å¯ä»¥æ‰“å¼€ç»ˆç«¯æŸ¥çœ‹ã€‚å¦‚æœä¸€ç›´å¡ç€ä¸åŠ¨æˆ–è€…é€Ÿåº¦å¾ˆæ…¢, åœ¨ç¡®ä¿¡ç½‘ç»œæ­£å¸¸çš„æƒ…å†µä¸‹è¯·å°è¯•é‡å¯WebUIã€‚<br>3. è‹¥ä¸‹è½½å¤±è´¥, ä¼šåœ¨æ¨¡å‹ç›®å½•**ç•™ä¸‹ä¸€ä¸ªæŸåçš„æ¨¡å‹**, è¯·**åŠ¡å¿…**æ‰“å¼€æ¨¡å‹ç›®å½•æ‰‹åŠ¨åˆ é™¤! <br>4. ç‚¹å‡»â€œé‡å¯WebUIâ€æŒ‰é’®å, ä¼šçŸ­æš‚æ€§çš„å¤±å»è¿æ¥, éšåä¼šè‡ªåŠ¨å¼€å¯ä¸€ä¸ªæ–°ç½‘é¡µã€‚"))
                            gr.Markdown(i18n("### æ¨¡å‹ä¸‹è½½é“¾æ¥"))
                            gr.Markdown(i18n("1. è‡ªåŠ¨ä»Github, Huggingfaceæˆ–é•œåƒç«™ä¸‹è½½æ¨¡å‹ã€‚<br>2. ä½ ä¹Ÿå¯ä»¥åœ¨æ­¤æ•´åˆåŒ…ä¸‹è½½é“¾æ¥ä¸­çš„All_Modelsæ–‡ä»¶å¤¹ä¸­æ‰¾åˆ°æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹å¹¶ä¸‹è½½ã€‚"))
                            gr.Markdown(value=i18n("### æ¨¡å‹å®‰è£…å®Œæˆå, éœ€é‡å¯WebUIåˆ·æ–°æ¨¡å‹åˆ—è¡¨"))
                with gr.TabItem(label=i18n("å®‰è£…éå®˜æ–¹MSSTæ¨¡å‹")):
                    gr.Markdown(value=i18n("ä½ å¯ä»¥ä»å…¶ä»–é€”å¾„è·å–éå®˜æ–¹MSSTæ¨¡å‹, åœ¨æ­¤é¡µé¢å®Œæˆé…ç½®æ–‡ä»¶è®¾ç½®å, å³å¯æ­£å¸¸ä½¿ç”¨ã€‚<br>æ³¨æ„: ä»…æ”¯æŒ'.ckpt', '.th', '.chpt'æ ¼å¼çš„æ¨¡å‹ã€‚æ¨¡å‹æ˜¾ç¤ºåå­—ä¸ºæ¨¡å‹æ–‡ä»¶åã€‚<br>é€‰æ‹©æ¨¡å‹ç±»å‹: å…±æœ‰ä¸‰ä¸ªå¯é€‰é¡¹ã€‚ä¾æ¬¡ä»£è¡¨äººå£°ç›¸å…³æ¨¡å‹, å¤šéŸ³è½¨åˆ†ç¦»æ¨¡å‹, å•éŸ³è½¨åˆ†ç¦»æ¨¡å‹ã€‚ä»…ç”¨äºåŒºåˆ†æ¨¡å‹å¤§è‡´ç±»å‹, å¯ä»»æ„é€‰æ‹©ã€‚<br>é€‰æ‹©æ¨¡å‹ç±»åˆ«: æ­¤é€‰é¡¹å…³ç³»åˆ°æ¨¡å‹æ˜¯å¦èƒ½æ­£å¸¸æ¨ç†ä½¿ç”¨, å¿…é¡»å‡†ç¡®é€‰æ‹©!"))
                    with gr.Row():
                        unmsst_model = gr.File(label=i18n("ä¸Šä¼ éå®˜æ–¹MSSTæ¨¡å‹"), type="filepath")
                        unmsst_config = gr.File(label=i18n("ä¸Šä¼ éå®˜æ–¹MSSTæ¨¡å‹é…ç½®æ–‡ä»¶"), type="filepath")
                    with gr.Row():
                        unmodel_class = gr.Dropdown(label=i18n("é€‰æ‹©æ¨¡å‹ç±»å‹"), choices=["vocal_models", "multi_stem_models", "single_stem_models"], interactive=True)
                        unmodel_type = gr.Dropdown(label=i18n("é€‰æ‹©æ¨¡å‹ç±»åˆ«"), choices=MODEL_TYPE, interactive=True)
                        unmsst_model_link = gr.Textbox(label=i18n("æ¨¡å‹ä¸‹è½½é“¾æ¥ (éå¿…é¡»ï¼Œè‹¥æ— ï¼Œå¯è·³è¿‡)"), value="", interactive=True, scale=2)
                    unmsst_model_install = gr.Button(i18n("å®‰è£…éå®˜æ–¹MSSTæ¨¡å‹"), variant="primary")
                    output_message_unmsst = gr.Textbox(label="Output Message")
                with gr.TabItem(label=i18n("å®‰è£…éå®˜æ–¹VRæ¨¡å‹")):
                    gr.Markdown(value=i18n("ä½ å¯ä»¥ä»å…¶ä»–é€”å¾„è·å–éå®˜æ–¹UVRæ¨¡å‹, åœ¨æ­¤é¡µé¢å®Œæˆé…ç½®æ–‡ä»¶è®¾ç½®å, å³å¯æ­£å¸¸ä½¿ç”¨ã€‚<br>æ³¨æ„: ä»…æ”¯æŒ'.pth'æ ¼å¼çš„æ¨¡å‹ã€‚æ¨¡å‹æ˜¾ç¤ºåå­—ä¸ºæ¨¡å‹æ–‡ä»¶åã€‚"))
                    with gr.Row():
                        unvr_model = gr.File(label=i18n("ä¸Šä¼ éå®˜æ–¹VRæ¨¡å‹"), type="filepath")
                        with gr.Column():
                            with gr.Row():
                                unvr_primary_stem = gr.Textbox(label=i18n("ä¸»è¦éŸ³è½¨åç§°"), value="", interactive=True)
                                unvr_secondary_stem = gr.Textbox(label=i18n("æ¬¡è¦éŸ³è½¨åç§°"), value="", interactive=True)
                            model_param = gr.Dropdown(label=i18n("é€‰æ‹©æ¨¡å‹å‚æ•°"), choices=get_all_model_param(), interactive=True)
                            with gr.Row():
                                is_karaoke_model = gr.Checkbox(label=i18n("æ˜¯å¦ä¸ºKaraokeæ¨¡å‹"), value=False, interactive=True)
                                is_BV_model = gr.Checkbox(label=i18n("æ˜¯å¦ä¸ºBVæ¨¡å‹"), value=False, interactive=True)
                                is_VR51_model = gr.Checkbox(label=i18n("æ˜¯å¦ä¸ºVR 5.1æ¨¡å‹"), value=False, interactive=True)
                    balance_value = gr.Number(label="balance_value", value=0.0, minimum=0.0, maximum=0.9, step=0.1, interactive=True, visible=False)
                    with gr.Row():
                        out_channels = gr.Number(label="Out Channels", value=32, minimum=1, step=1, interactive=True, visible=False)
                        out_channels_lstm = gr.Number(label="Out Channels (LSTM layer)", value=128, minimum=1, step=1, interactive=True, visible=False)
                    upload_param = gr.File(label=i18n("ä¸Šä¼ å‚æ•°æ–‡ä»¶"), type="filepath", interactive=True, visible=False)
                    unvr_model_link = gr.Textbox(label=i18n("æ¨¡å‹ä¸‹è½½é“¾æ¥ (éå¿…é¡»ï¼Œè‹¥æ— ï¼Œå¯è·³è¿‡)"), value="", interactive=True)
                    unvr_model_install = gr.Button(i18n("å®‰è£…éå®˜æ–¹VRæ¨¡å‹"), variant="primary")
                    output_message_unvr = gr.Textbox(label="Output Message")

            model_type_dropdown.change(fn=upgrade_download_model_name,inputs=[model_type_dropdown],outputs=[download_model_name_dropdown])
            download_button.click(fn=download_model,inputs=[model_type_dropdown, download_model_name_dropdown],outputs=output_message_download)
            manual_download_button.click(fn=manual_download_model,inputs=[model_type_dropdown, download_model_name_dropdown],outputs=output_message_download)
            open_model_dir.click(open_folder, inputs=gr.Textbox(MODEL_FOLDER, visible=False))
            open_uvr_model_dir.click(open_folder, inputs=gr.Textbox(uvr_model_folder, visible=False))
            restart_webui.click(webui_restart)
            is_BV_model.change(fn=update_vr_param, inputs=[is_BV_model, is_VR51_model, model_param], outputs=[balance_value, out_channels, out_channels_lstm, upload_param])
            is_VR51_model.change(fn=update_vr_param, inputs=[is_BV_model, is_VR51_model, model_param], outputs=[balance_value, out_channels, out_channels_lstm, upload_param])
            model_param.change(fn=update_vr_param, inputs=[is_BV_model, is_VR51_model, model_param], outputs=[balance_value, out_channels, out_channels_lstm, upload_param])
            unmsst_model_install.click(fn=install_unmsst_model, inputs=[unmsst_model, unmsst_config, unmodel_class, unmodel_type, unmsst_model_link], outputs=output_message_unmsst)
            unvr_model_install.click(fn=install_unvr_model, inputs=[unvr_model, unvr_primary_stem, unvr_secondary_stem, model_param, is_karaoke_model, is_BV_model, is_VR51_model, balance_value, out_channels, out_channels_lstm, upload_param, unvr_model_link], outputs=output_message_unvr)

        with gr.TabItem(label=i18n("MSSTè®­ç»ƒ")):
            gr.Markdown(value=i18n("æ­¤é¡µé¢æä¾›æ•°æ®é›†åˆ¶ä½œæ•™ç¨‹, è®­ç»ƒå‚æ•°é€‰æ‹©, ä»¥åŠä¸€é”®è®­ç»ƒã€‚æœ‰å…³é…ç½®æ–‡ä»¶çš„ä¿®æ”¹å’Œæ•°æ®é›†æ–‡ä»¶å¤¹çš„è¯¦ç»†è¯´æ˜è¯·å‚è€ƒMSSTåŸé¡¹ç›®: [https://github.com/ZFTurbo/Music-Source-Separation-Training](https://github.com/ZFTurbo/Music-Source-Separation-Training)<br>åœ¨å¼€å§‹ä¸‹æ–¹çš„æ¨¡å‹è®­ç»ƒä¹‹å‰, è¯·å…ˆè¿›è¡Œè®­ç»ƒæ•°æ®çš„åˆ¶ä½œã€‚<br>è¯´æ˜: æ•°æ®é›†ç±»å‹å³è®­ç»ƒé›†åˆ¶ä½œStep 1ä¸­ä½ é€‰æ‹©çš„ç±»å‹, 1: Type1; 2: Type2; 3: Type3; 4: Type4, å¿…é¡»ä¸ä½ çš„æ•°æ®é›†ç±»å‹ç›¸åŒ¹é…ã€‚"))
            with gr.Tabs():
                with gr.TabItem(label=i18n("è®­ç»ƒ")):
                    with gr.Row():
                        train_model_type = gr.Dropdown(label=i18n("é€‰æ‹©è®­ç»ƒæ¨¡å‹ç±»å‹"),choices=MODEL_TYPE,value=webui_config['training']['model_type'] if webui_config['training']['model_type'] else None,interactive=True,scale=1)
                        train_config_path = gr.Textbox(label=i18n("é…ç½®æ–‡ä»¶è·¯å¾„"),value=webui_config['training']['config_path'] if webui_config['training']['config_path'] else i18n("è¯·è¾“å…¥é…ç½®æ–‡ä»¶è·¯å¾„æˆ–é€‰æ‹©é…ç½®æ–‡ä»¶"),interactive=True,scale=3)
                        select_train_config_path = gr.Button(i18n("é€‰æ‹©é…ç½®æ–‡ä»¶"), scale=1)
                    with gr.Row():
                        train_dataset_type = gr.Dropdown(label=i18n("æ•°æ®é›†ç±»å‹"),choices=[1, 2, 3, 4],value=webui_config['training']['dataset_type'] if webui_config['training']['dataset_type'] else None,interactive=True,scale=1)
                        train_dataset_path = gr.Textbox(label=i18n("æ•°æ®é›†è·¯å¾„"),value=webui_config['training']['dataset_path'] if webui_config['training']['dataset_path'] else i18n("è¯·è¾“å…¥æˆ–é€‰æ‹©æ•°æ®é›†æ–‡ä»¶å¤¹"),interactive=True,scale=3)
                        select_train_dataset_path = gr.Button(i18n("é€‰æ‹©æ•°æ®é›†æ–‡ä»¶å¤¹"), scale=1)
                    with gr.Row():
                        train_valid_path = gr.Textbox(label=i18n("éªŒè¯é›†è·¯å¾„"),value=webui_config['training']['valid_path'] if webui_config['training']['valid_path'] else i18n("è¯·è¾“å…¥æˆ–é€‰æ‹©éªŒè¯é›†æ–‡ä»¶å¤¹"),interactive=True,scale=4)
                        select_train_valid_path = gr.Button(i18n("é€‰æ‹©éªŒè¯é›†æ–‡ä»¶å¤¹"), scale=1)
                    with gr.Row():
                        train_num_workers = gr.Number(label=i18n("num_workers: æ•°æ®é›†è¯»å–çº¿ç¨‹æ•°, 0ä¸ºè‡ªåŠ¨"),value=webui_config['training']['num_workers'] if webui_config['training']['num_workers'] else 0,interactive=True,minimum=0,maximum=cpu_count(),step=1)
                        train_device_ids = gr.Textbox(label=i18n("device_ids: é€‰æ‹©æ˜¾å¡, å¤šå¡ç”¨æˆ·è¯·ä½¿ç”¨ç©ºæ ¼åˆ†éš”"),value=webui_config['training']['device_ids'] if webui_config['training']['device_ids'] else "0",interactive=True)
                        train_seed = gr.Number(label=i18n("éšæœºæ•°ç§å­, 0ä¸ºéšæœº"), value="0")
                    with gr.Row():
                        train_pin_memory = gr.Checkbox(label=i18n("æ˜¯å¦å°†åŠ è½½çš„æ•°æ®æ”¾ç½®åœ¨å›ºå®šå†…å­˜ä¸­, é»˜è®¤ä¸ºå¦"), value=webui_config['training']['pin_memory'], interactive=True)
                        train_accelerate = gr.Checkbox(label=i18n("æ˜¯å¦ä½¿ç”¨åŠ é€Ÿè®­ç»ƒ, å¯¹äºå¤šæ˜¾å¡ç”¨æˆ·ä¼šåŠ å¿«è®­ç»ƒ"), value=webui_config['training']['accelerate'], interactive=True)
                        train_pre_validate = gr.Checkbox(label=i18n("æ˜¯å¦åœ¨è®­ç»ƒå‰éªŒè¯æ¨¡å‹, ä»…å¯¹åŠ é€Ÿè®­ç»ƒæœ‰æ•ˆ"), value=webui_config['training']['pre_valid'], interactive=True)
                    with gr.Row():
                        train_use_multistft_loss = gr.Checkbox(label=i18n("æ˜¯å¦ä½¿ç”¨MultiSTFT Loss, é»˜è®¤ä¸ºå¦"), value=webui_config['training']['use_multistft_loss'], interactive=True)
                        train_use_mse_loss = gr.Checkbox(label=i18n("æ˜¯å¦ä½¿ç”¨MSE loss, é»˜è®¤ä¸ºå¦"), value=webui_config['training']['use_mse_loss'], interactive=True)
                        train_use_l1_loss = gr.Checkbox(label=i18n("æ˜¯å¦ä½¿ç”¨L1 loss, é»˜è®¤ä¸ºå¦"), value=webui_config['training']['use_l1_loss'], interactive=True)
                    with gr.Row():
                        train_results_path = gr.Textbox(label=i18n("æ¨¡å‹ä¿å­˜è·¯å¾„"),value=webui_config['training']['results_path'] if webui_config['training']['results_path'] else i18n("è¯·è¾“å…¥æˆ–é€‰æ‹©æ¨¡å‹ä¿å­˜æ–‡ä»¶å¤¹"),interactive=True,scale=3)
                        select_train_results_path = gr.Button(i18n("é€‰æ‹©æ–‡ä»¶å¤¹"), scale=1)
                        open_train_results_path = gr.Button(i18n("æ‰“å¼€æ–‡ä»¶å¤¹"), scale=1)
                    with gr.Row():
                        train_start_check_point = gr.Dropdown(label=i18n("åˆå§‹æ¨¡å‹: ç»§ç»­è®­ç»ƒæˆ–å¾®è°ƒæ¨¡å‹è®­ç»ƒæ—¶, è¯·é€‰æ‹©åˆå§‹æ¨¡å‹, å¦åˆ™å°†ä»å¤´å¼€å§‹è®­ç»ƒ! "), choices=["None"], value="None", interactive=True, scale=4)
                        reflesh_start_check_point = gr.Button(i18n("åˆ·æ–°åˆå§‹æ¨¡å‹åˆ—è¡¨"), scale=1)
                    save_train_config = gr.Button(i18n("ä¿å­˜ä¸Šè¿°è®­ç»ƒé…ç½®"))
                    start_train_button = gr.Button(i18n("å¼€å§‹è®­ç»ƒ"), variant="primary")
                    gr.Markdown(value=i18n("ç‚¹å‡»å¼€å§‹è®­ç»ƒå, è¯·åˆ°ç»ˆç«¯æŸ¥çœ‹è®­ç»ƒè¿›åº¦æˆ–æŠ¥é”™, ä¸‹æ–¹ä¸ä¼šè¾“å‡ºæŠ¥é”™ä¿¡æ¯, æƒ³è¦åœæ­¢è®­ç»ƒå¯ä»¥ç›´æ¥å…³é—­ç»ˆç«¯ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­, ä½ ä¹Ÿå¯ä»¥å…³é—­ç½‘é¡µ, ä»…**ä¿ç•™ç»ˆç«¯**ã€‚"))
                    with gr.Row():
                        output_message_train = gr.Textbox(label="Output Message", scale=4)
                        stop_thread = gr.Button(i18n("å¼ºåˆ¶åœæ­¢"), scale=1)

                    select_train_config_path.click(fn=select_yaml_file, outputs=train_config_path)
                    select_train_dataset_path.click(fn=select_folder, outputs=train_dataset_path)
                    select_train_valid_path.click(fn=select_folder, outputs=train_valid_path)
                    select_train_results_path.click(fn=select_folder, outputs=train_results_path)
                    open_train_results_path.click(fn=open_folder, inputs=train_results_path)
                    save_train_config.click(fn=save_training_config,inputs=[train_model_type, train_config_path, train_dataset_type, train_dataset_path, train_valid_path, train_num_workers,train_device_ids, train_seed, train_pin_memory, train_use_multistft_loss, train_use_mse_loss, train_use_l1_loss, train_results_path, train_accelerate, train_pre_validate],outputs=output_message_train)
                    start_train_button.click(fn=start_training,inputs=[train_model_type, train_config_path, train_dataset_type, train_dataset_path, train_valid_path, train_num_workers, train_device_ids,train_seed, train_pin_memory, train_use_multistft_loss, train_use_mse_loss, train_use_l1_loss, train_results_path, train_start_check_point, train_accelerate, train_pre_validate],outputs=output_message_train)
                    reflesh_start_check_point.click(fn=update_train_start_check_point,inputs=train_results_path,outputs=train_start_check_point)
                    stop_thread.click(fn=stop_all_thread)

                with gr.TabItem(label=i18n("éªŒè¯")):
                    gr.Markdown(value=i18n("æ­¤é¡µé¢ç”¨äºæ‰‹åŠ¨éªŒè¯æ¨¡å‹æ•ˆæœ, æµ‹è¯•éªŒè¯é›†, è¾“å‡ºSDRæµ‹è¯•ä¿¡æ¯ã€‚è¾“å‡ºçš„ä¿¡æ¯ä¼šå­˜æ”¾åœ¨è¾“å‡ºæ–‡ä»¶å¤¹çš„results.txtä¸­ã€‚<br>ä¸‹æ–¹å‚æ•°å°†è‡ªåŠ¨åŠ è½½è®­ç»ƒé¡µé¢çš„å‚æ•°, åœ¨è®­ç»ƒé¡µé¢ç‚¹å‡»ä¿å­˜è®­ç»ƒå‚æ•°å, é‡å¯WebUIå³å¯è‡ªåŠ¨åŠ è½½ã€‚å½“ç„¶ä½ ä¹Ÿå¯ä»¥æ‰‹åŠ¨è¾“å…¥å‚æ•°ã€‚<br>"))
                    with gr.Row():
                        valid_model_type = gr.Dropdown(label=i18n("é€‰æ‹©æ¨¡å‹ç±»å‹"),choices=MODEL_TYPE,value=webui_config['training']['model_type'] if webui_config['training']['model_type'] else None,interactive=True,scale=1)
                        valid_config_path = gr.Textbox(label=i18n("é…ç½®æ–‡ä»¶è·¯å¾„"),value=webui_config['training']['config_path'] if webui_config['training']['config_path'] else i18n("è¯·è¾“å…¥é…ç½®æ–‡ä»¶è·¯å¾„æˆ–é€‰æ‹©é…ç½®æ–‡ä»¶"),interactive=True,scale=3)
                        select_valid_config_path = gr.Button(i18n("é€‰æ‹©é…ç½®æ–‡ä»¶"), scale=1)
                    with gr.Row():
                        valid_model_path = gr.Textbox(label=i18n("æ¨¡å‹è·¯å¾„"),value=i18n("è¯·è¾“å…¥æˆ–é€‰æ‹©æ¨¡å‹æ–‡ä»¶"),interactive=True,scale=4)
                        select_valid_model_path = gr.Button(i18n("é€‰æ‹©æ¨¡å‹æ–‡ä»¶"), scale=1)
                    with gr.Row():
                        valid_path = gr.Textbox(label=i18n("éªŒè¯é›†è·¯å¾„"),value=webui_config['training']['valid_path'] if webui_config['training']['valid_path'] else i18n("è¯·è¾“å…¥æˆ–é€‰æ‹©éªŒè¯é›†æ–‡ä»¶å¤¹"),interactive=True,scale=4)
                        select_valid_path = gr.Button(i18n("é€‰æ‹©éªŒè¯é›†æ–‡ä»¶å¤¹"), scale=1)
                    with gr.Row():
                        valid_results_path = gr.Textbox(label=i18n("è¾“å‡ºç›®å½•"),value="results/",interactive=True,scale=3)
                        select_valid_results_path = gr.Button(i18n("é€‰æ‹©æ–‡ä»¶å¤¹"), scale=1)
                        open_valid_results_path = gr.Button(i18n("æ‰“å¼€æ–‡ä»¶å¤¹"), scale=1)
                    with gr.Row():
                        valid_device_ids = gr.Textbox(label=i18n("é€‰æ‹©æ˜¾å¡, å¤šå¡ç”¨æˆ·è¯·ä½¿ç”¨ç©ºæ ¼åˆ†éš”GPU ID"),value=webui_config['training']['device_ids'] if webui_config['training']['device_ids'] else "0",interactive=True)
                        valid_num_workers = gr.Number(label=i18n("éªŒè¯é›†è¯»å–çº¿ç¨‹æ•°, 0ä¸ºè‡ªåŠ¨"),value=webui_config['training']['num_workers'] if webui_config['training']['num_workers'] else 0,interactive=True,minimum=0,maximum=cpu_count(),step=1)
                        valid_extension = gr.Dropdown(label=i18n("é€‰æ‹©éªŒè¯é›†éŸ³é¢‘æ ¼å¼"),choices=["wav", "flac", "mp3"],value="wav",interactive=True,allow_custom_value=True)
                    valid_pin_memory = gr.Checkbox(label=i18n("æ˜¯å¦å°†åŠ è½½çš„æ•°æ®æ”¾ç½®åœ¨å›ºå®šå†…å­˜ä¸­, é»˜è®¤ä¸ºå¦"), value=webui_config['training']['pin_memory'], interactive=True)
                    valid_button = gr.Button(i18n("å¼€å§‹éªŒè¯"), variant="primary")
                    with gr.Row():
                        valid_output_message = gr.Textbox(label="Output Message", scale=4)
                        stop_thread = gr.Button(i18n("å¼ºåˆ¶åœæ­¢"), scale=1)

                    select_valid_config_path.click(fn=select_yaml_file, outputs=valid_config_path)
                    select_valid_model_path.click(fn=select_file, outputs=valid_model_path)
                    select_valid_path.click(fn=select_folder, outputs=valid_path)
                    select_valid_results_path.click(fn=select_folder, outputs=valid_results_path)
                    open_valid_results_path.click(fn=open_folder, inputs=valid_results_path)
                    valid_button.click(fn=validate_model,inputs=[valid_model_type, valid_config_path, valid_model_path, valid_path, valid_results_path, valid_device_ids, valid_num_workers, valid_extension, valid_pin_memory],outputs=valid_output_message)
                    stop_thread.click(fn=stop_all_thread)

                with gr.TabItem(label=i18n("è®­ç»ƒé›†åˆ¶ä½œæŒ‡å—")):
                    with gr.Accordion(i18n("Step 1: æ•°æ®é›†åˆ¶ä½œ"), open=False):
                        gr.Markdown(value=i18n("è¯·**ä»»é€‰ä¸‹é¢å››ç§ç±»å‹ä¹‹ä¸€**åˆ¶ä½œæ•°æ®é›†æ–‡ä»¶å¤¹, å¹¶æŒ‰ç…§ç»™å‡ºçš„ç›®å½•å±‚çº§æ”¾ç½®ä½ çš„è®­ç»ƒæ•°æ®ã€‚å®Œæˆå, è®°å½•ä½ çš„æ•°æ®é›†**æ–‡ä»¶å¤¹è·¯å¾„**ä»¥åŠä½ é€‰æ‹©çš„**æ•°æ®é›†ç±»å‹**, ä»¥ä¾¿åç»­ä½¿ç”¨ã€‚"))
                        with gr.Row():
                            with gr.Column():
                                gr.Markdown("# Type 1 (MUSDB)")
                                gr.Markdown(i18n("ä¸åŒçš„æ–‡ä»¶å¤¹ã€‚æ¯ä¸ªæ–‡ä»¶å¤¹åŒ…å«æ‰€éœ€çš„æ‰€æœ‰stems, æ ¼å¼ä¸ºstem_name.wavã€‚ä¸MUSDBHQ18æ•°æ®é›†ç›¸åŒã€‚åœ¨æœ€æ–°çš„ä»£ç ç‰ˆæœ¬ä¸­, å¯ä»¥ä½¿ç”¨flacæ›¿ä»£wavã€‚<br>ä¾‹å¦‚: "))
                                gr.Markdown("""
                                    your_datasets_folder<br>
                                    â”œâ”€â”€â”€Song 1<br>
                                    â”‚   â”œâ”€â”€â”€vocals.wav<br>
                                    â”‚   â”œâ”€â”€â”€bass.wav<br>
                                    â”‚   â”œâ”€â”€â”€drums.wav<br>
                                    â”‚   â””â”€â”€â”€other.wav<br>
                                    â”œâ”€â”€â”€Song 2<br>
                                    â”‚   â”œâ”€â”€â”€vocals.wav<br>
                                    â”‚   â”œâ”€â”€â”€bass.wav<br>
                                    â”‚   â”œâ”€â”€â”€drums.wav<br>
                                    â”‚   â””â”€â”€â”€other.wav<br>
                                    â”œâ”€â”€â”€Song 3<br>
                                        â””â”€â”€â”€...<br>
                                    """)
                            with gr.Column():
                                gr.Markdown("# Type 2 (Stems)")
                                gr.Markdown(i18n("æ¯ä¸ªæ–‡ä»¶å¤¹æ˜¯stem_nameã€‚æ–‡ä»¶å¤¹ä¸­åŒ…å«ä»…ç”±æ‰€éœ€stemç»„æˆçš„wavæ–‡ä»¶ã€‚<br>ä¾‹å¦‚: "))
                                gr.Markdown("""
                                    your_datasets_folder<br>
                                    â”œâ”€â”€â”€vocals<br>
                                    â”‚   â”œâ”€â”€â”€vocals_1.wav<br>
                                    â”‚   â”œâ”€â”€â”€vocals_2.wav<br>
                                    â”‚   â”œâ”€â”€â”€vocals_3.wav<br>
                                    â”‚   â””â”€â”€â”€...<br>
                                    â”œâ”€â”€â”€bass<br>
                                    â”‚   â”œâ”€â”€â”€bass_1.wav<br>
                                    â”‚   â”œâ”€â”€â”€bass_2.wav<br>
                                    â”‚   â”œâ”€â”€â”€bass_3.wav<br>
                                    â”‚   â””â”€â”€â”€...<br>
                                    â”œâ”€â”€â”€drums<br>
                                        â””â”€â”€â”€...<br>
                                    """)
                            with gr.Column():
                                gr.Markdown("# Type 3 (CSV file)")
                                gr.Markdown(i18n("å¯ä»¥æä¾›ä»¥ä¸‹ç»“æ„çš„CSVæ–‡ä»¶ (æˆ–CSVæ–‡ä»¶åˆ—è¡¨) <br>ä¾‹å¦‚: "))
                                gr.Markdown("""
                                    instrum,path<br>
                                    vocals,/path/to/dataset/vocals_1.wav<br>
                                    vocals,/path/to/dataset2/vocals_v2.wav<br>
                                    vocals,/path/to/dataset3/vocals_some.wav<br>
                                    ...<br>
                                    drums,/path/to/dataset/drums_good.wav<br>
                                    ...<br>
                                    """)
                            with gr.Column():
                                gr.Markdown("# Type 4 (MUSDB Aligned)")
                                gr.Markdown(i18n("ä¸ç±»å‹1ç›¸åŒ, ä½†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ‰€æœ‰ä¹å™¨éƒ½å°†æ¥è‡ªæ­Œæ›²çš„ç›¸åŒä½ç½®ã€‚<br>ä¾‹å¦‚: "))
                                gr.Markdown("""
                                    your_datasets_folder<br>
                                    â”œâ”€â”€â”€Song 1<br>
                                    â”‚   â”œâ”€â”€â”€vocals.wav<br>
                                    â”‚   â”œâ”€â”€â”€bass.wav<br>
                                    â”‚   â”œâ”€â”€â”€drums.wav<br>
                                    â”‚   â””â”€â”€â”€other.wav<br>
                                    â”œâ”€â”€â”€Song 2<br>
                                    â”‚   â”œâ”€â”€â”€vocals.wav<br>
                                    â”‚   â”œâ”€â”€â”€bass.wav<br>
                                    â”‚   â”œâ”€â”€â”€drums.wav<br>
                                    â”‚   â””â”€â”€â”€other.wav<br>
                                    â”œâ”€â”€â”€Song 3<br>
                                        â””â”€â”€â”€...<br>
                                    """)
                    with gr.Accordion(i18n("Step 2: éªŒè¯é›†åˆ¶ä½œ"), open=False):
                        gr.Markdown(value=i18n("éªŒè¯é›†åˆ¶ä½œã€‚éªŒè¯æ•°æ®é›†**å¿…é¡»**ä¸ä¸Šé¢æ•°æ®é›†åˆ¶ä½œçš„Type 1(MUSDB)æ•°æ®é›†**ç»“æ„ç›¸åŒ** (**æ— è®ºä½ ä½¿ç”¨å“ªç§ç±»å‹çš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒ**) , æ­¤å¤–æ¯ä¸ªæ–‡ä»¶å¤¹è¿˜å¿…é¡»åŒ…å«æ¯é¦–æ­Œçš„mixture.wav, mixture.wavæ˜¯æ‰€æœ‰stemçš„æ€»å’Œ<br>ä¾‹å¦‚: "))
                        gr.Markdown("""
                            your_datasets_folder<br>
                            â”œâ”€â”€â”€Song 1<br>
                            â”‚   â”œâ”€â”€â”€vocals.wav<br>
                            â”‚   â”œâ”€â”€â”€bass.wav<br>
                            â”‚   â”œâ”€â”€â”€drums.wav<br>
                            â”‚   â”œâ”€â”€â”€other.wav<br>
                            â”‚   â””â”€â”€â”€mixture.wav<br>
                            â”œâ”€â”€â”€Song 2<br>
                            â”‚   â”œâ”€â”€â”€vocals.wav<br>
                            â”‚   â”œâ”€â”€â”€bass.wav<br>
                            â”‚   â”œâ”€â”€â”€drums.wav<br>
                            â”‚   â”œâ”€â”€â”€other.wav<br>
                            â”‚   â””â”€â”€â”€mixture.wav<br>
                            â”œâ”€â”€â”€Song 3<br>
                                â””â”€â”€â”€...<br>
                            """)
                    with gr.Accordion(i18n("Step 3: é€‰æ‹©å¹¶ä¿®æ”¹ä¿®æ”¹é…ç½®æ–‡ä»¶"), open=False):
                        gr.Markdown(value=i18n("è¯·å…ˆæ˜ç¡®ä½ æƒ³è¦è®­ç»ƒçš„æ¨¡å‹ç±»å‹, ç„¶åé€‰æ‹©å¯¹åº”çš„é…ç½®æ–‡ä»¶è¿›è¡Œä¿®æ”¹ã€‚<br>ç›®å‰æœ‰ä»¥ä¸‹å‡ ç§æ¨¡å‹ç±»å‹: ") + str(MODEL_TYPE) + i18n("<br>ç¡®å®šå¥½æ¨¡å‹ç±»å‹å, ä½ å¯ä»¥å‰å¾€æ•´åˆåŒ…æ ¹ç›®å½•ä¸­çš„configs_backupæ–‡ä»¶å¤¹ä¸‹æ‰¾åˆ°å¯¹åº”çš„é…ç½®æ–‡ä»¶æ¨¡æ¿ã€‚å¤åˆ¶ä¸€ä»½æ¨¡æ¿, ç„¶åæ ¹æ®ä½ çš„éœ€æ±‚è¿›è¡Œä¿®æ”¹ã€‚ä¿®æ”¹å®Œæˆåè®°ä¸‹ä½ çš„é…ç½®æ–‡ä»¶è·¯å¾„, ä»¥ä¾¿åç»­ä½¿ç”¨ã€‚<br>ç‰¹åˆ«è¯´æ˜: config_musdb18_xxx.yamlæ˜¯é’ˆå¯¹MUSDB18æ•°æ®é›†çš„é…ç½®æ–‡ä»¶ã€‚<br>"))
                        open_config_template = gr.Button(
                            i18n("æ‰“å¼€é…ç½®æ–‡ä»¶æ¨¡æ¿æ–‡ä»¶å¤¹"), variant="primary")
                        open_config_template.click(open_folder, inputs=gr.Textbox("configs_backup", visible=False))
                        gr.Markdown(value=i18n("ä½ å¯ä»¥ä½¿ç”¨ä¸‹è¡¨æ ¹æ®ä½ çš„GPUé€‰æ‹©ç”¨äºè®­ç»ƒçš„BS_Roformeræ¨¡å‹çš„batch_sizeå‚æ•°ã€‚è¡¨ä¸­æä¾›çš„æ‰¹é‡å¤§å°å€¼é€‚ç”¨äºå•ä¸ªGPUã€‚å¦‚æœä½ æœ‰å¤šä¸ªGPU, åˆ™éœ€è¦å°†è¯¥å€¼ä¹˜ä»¥GPUçš„æ•°é‡ã€‚"))
                        roformer_data = {
                            "chunk_size": [131584, 131584, 131584, 131584, 131584, 131584, 263168, 263168, 352800, 352800, 352800, 352800],
                            "dim": [128, 256, 384, 512, 256, 256, 128, 256, 128, 256, 384, 512],
                            "depth": [6, 6, 6, 6, 8, 12, 6, 6, 6, 6, 12, 12],
                            "batch_size (A6000 48GB)": [10, 8, 7, 6, 6, 4, 4, 3, 2, 2, 1, '-'],
                            "batch_size (3090/4090 24GB)": [5, 4, 3, 3, 3, 2, 2, 1, 1, 1, '-', '-'],
                            "batch_size (16GB)": [3, 2, 2, 2, 2, 1, 1, 1, '-', '-', '-', '-']
                        }
                        gr.DataFrame(pd.DataFrame(roformer_data))
                    with gr.Accordion(i18n("Step 4: æ•°æ®å¢å¼º"), open=False):
                        gr.Markdown(value=i18n("æ•°æ®å¢å¼ºå¯ä»¥åŠ¨æ€æ›´æ”¹stem, é€šè¿‡ä»æ—§æ ·æœ¬åˆ›å»ºæ–°æ ·æœ¬æ¥å¢åŠ æ•°æ®é›†çš„å¤§å°ã€‚ç°åœ¨, æ•°æ®å¢å¼ºçš„æ§åˆ¶åœ¨é…ç½®æ–‡ä»¶ä¸­è¿›è¡Œã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªåŒ…å«æ‰€æœ‰å¯ç”¨æ•°æ®å¢å¼ºçš„å®Œæ•´é…ç½®ç¤ºä¾‹ã€‚ä½ å¯ä»¥å°†å…¶å¤åˆ¶åˆ°ä½ çš„é…ç½®æ–‡ä»¶ä¸­ä»¥ä½¿ç”¨æ•°æ®å¢å¼ºã€‚<br>æ³¨æ„:<br>1. è¦å®Œå…¨ç¦ç”¨æ‰€æœ‰æ•°æ®å¢å¼º, å¯ä»¥ä»é…ç½®æ–‡ä»¶ä¸­åˆ é™¤augmentationséƒ¨åˆ†æˆ–å°†enableè®¾ç½®ä¸ºfalseã€‚<br>2. å¦‚æœè¦ç¦ç”¨æŸäº›æ•°æ®å¢å¼º, åªéœ€å°†å…¶è®¾ç½®ä¸º0ã€‚<br>3. alléƒ¨åˆ†ä¸­çš„æ•°æ®å¢å¼ºåº”ç”¨äºæ‰€æœ‰stemã€‚<br>4. vocals/bassç­‰éƒ¨åˆ†ä¸­çš„æ•°æ®å¢å¼ºä»…åº”ç”¨äºç›¸åº”çš„stemã€‚ä½ å¯ä»¥ä¸ºtraining.instrumentsä¸­ç»™å‡ºçš„æ‰€æœ‰stemåˆ›å»ºè¿™æ ·çš„éƒ¨åˆ†ã€‚"))
                        augmentations_config = load_augmentations_config()
                        gr.Code(value=augmentations_config, language="yaml")

        with gr.TabItem(label=i18n("è®¾ç½®")):
            with gr.Row():
                with gr.Column(scale=3):
                    with gr.Row():
                        gpu_list = gr.Textbox(label=i18n("GPUä¿¡æ¯"), value=get_device(), interactive=False)
                        plantform_info = gr.Textbox(label=i18n("ç³»ç»Ÿä¿¡æ¯"), value=get_platform(), interactive=False)
                    with gr.Row():
                        set_webui_port = gr.Number(label=i18n("è®¾ç½®WebUIç«¯å£, 0ä¸ºè‡ªåŠ¨"), value=webui_config["settings"].get("port", 0), interactive=True)
                        set_language = gr.Dropdown(label=i18n("é€‰æ‹©è¯­è¨€"), choices=language_dict.keys(), value=get_language(), interactive=True)
                        set_download_link = gr.Dropdown(label=i18n("é€‰æ‹©MSSTæ¨¡å‹ä¸‹è½½é“¾æ¥"), choices=["Auto", i18n("huggingface.co (éœ€è¦é­”æ³•)"), i18n("hf-mirror.com (é•œåƒç«™å¯ç›´è¿)")], value=webui_config['settings']['download_link'] if webui_config['settings']['download_link'] else "Auto", interactive=True)
                    with gr.Row():
                        open_local_link = gr.Checkbox(label=i18n("å¯¹æœ¬åœ°å±€åŸŸç½‘å¼€æ”¾WebUI: å¼€å¯å, åŒä¸€å±€åŸŸç½‘å†…çš„è®¾å¤‡å¯é€šè¿‡'æœ¬æœºIP:ç«¯å£'çš„æ–¹å¼è®¿é—®WebUIã€‚"), value=webui_config['settings']['local_link'], interactive=True)
                        open_share_link = gr.Checkbox(label=i18n("å¼€å¯å…¬å…±é“¾æ¥: å¼€å¯å, ä»–äººå¯é€šè¿‡å…¬å…±é“¾æ¥è®¿é—®WebUIã€‚é“¾æ¥æœ‰æ•ˆæ—¶é•¿ä¸º72å°æ—¶ã€‚"), value=webui_config['settings']['share_link'], interactive=True)
                    with gr.Row():
                        select_uvr_model_dir = gr.Textbox(label=i18n("é€‰æ‹©UVRæ¨¡å‹ç›®å½•"),value=webui_config['settings']['uvr_model_dir'] if webui_config['settings']['uvr_model_dir'] else "pretrain/VR_Models",interactive=True,scale=4)
                        select_uvr_model_dir_button = gr.Button(i18n("é€‰æ‹©æ–‡ä»¶å¤¹"), scale=1)
                    with gr.Row():
                        update_message = gr.Textbox(label=i18n("æ£€æŸ¥æ›´æ–°"), value=i18n("å½“å‰ç‰ˆæœ¬: ") + PACKAGE_VERSION + i18n(", è¯·ç‚¹å‡»æ£€æŸ¥æ›´æ–°æŒ‰é’®"), interactive=False,scale=3)
                        check_update = gr.Button(i18n("æ£€æŸ¥æ›´æ–°"), scale=1)
                        goto_github = gr.Button(i18n("å‰å¾€Githubç…ä¸€çœ¼"))
                    with gr.Row():
                        reset_all_webui_config = gr.Button(i18n("é‡ç½®WebUIè·¯å¾„è®°å½•"), variant="primary")
                        reset_seetings = gr.Button(i18n("é‡ç½®WebUIè®¾ç½®"), variant="primary")
                    restart_webui = gr.Button(i18n("é‡å¯WebUI"), variant="primary")
                    setting_output_message = gr.Textbox(label="Output Message")
                with gr.Column(scale=1):
                    gr.Markdown(i18n("### è®¾ç½®è¯´æ˜"))
                    gr.Markdown(i18n("### é€‰æ‹©UVRæ¨¡å‹ç›®å½•"))
                    gr.Markdown(i18n("å¦‚æœä½ çš„ç”µè„‘ä¸­æœ‰å®‰è£…UVR5, ä½ ä¸å¿…é‡æ–°ä¸‹è½½ä¸€éUVR5æ¨¡å‹, åªéœ€åœ¨ä¸‹æ–¹â€œé€‰æ‹©UVRæ¨¡å‹ç›®å½•â€ä¸­é€‰æ‹©ä½ çš„UVR5æ¨¡å‹ç›®å½•, å®šä½åˆ°models/VR_Modelsæ–‡ä»¶å¤¹ã€‚<br>ä¾‹å¦‚: E:/Program Files/Ultimate Vocal Remover/models/VR_Models ç‚¹å‡»ä¿å­˜è®¾ç½®æˆ–é‡ç½®è®¾ç½®å, éœ€è¦é‡å¯WebUIä»¥æ›´æ–°ã€‚"))
                    gr.Markdown(i18n("### æ£€æŸ¥æ›´æ–°"))
                    gr.Markdown(i18n("ä»Githubæ£€æŸ¥æ›´æ–°, éœ€è¦ä¸€å®šçš„ç½‘ç»œè¦æ±‚ã€‚ç‚¹å‡»æ£€æŸ¥æ›´æ–°æŒ‰é’®å, ä¼šè‡ªåŠ¨æ£€æŸ¥æ˜¯å¦æœ‰æœ€æ–°ç‰ˆæœ¬ã€‚ä½ å¯ä»¥å‰å¾€æ­¤æ•´åˆåŒ…çš„ä¸‹è½½é“¾æ¥æˆ–è®¿é—®Githubä»“åº“ä¸‹è½½æœ€æ–°ç‰ˆæœ¬ã€‚"))
                    gr.Markdown(i18n("### é‡ç½®WebUIè·¯å¾„è®°å½•"))
                    gr.Markdown(i18n("å°†æ‰€æœ‰è¾“å…¥è¾“å‡ºç›®å½•é‡ç½®ä¸ºé»˜è®¤è·¯å¾„, é¢„è®¾/æ¨¡å‹/é…ç½®æ–‡ä»¶ä»¥åŠä¸Šé¢çš„è®¾ç½®ç­‰**ä¸ä¼šé‡ç½®**, æ— éœ€æ‹…å¿ƒã€‚é‡ç½®WebUIè®¾ç½®å, éœ€è¦é‡å¯WebUIã€‚"))
                    gr.Markdown(i18n("### é‡ç½®WebUIè®¾ç½®"))
                    gr.Markdown(i18n("ä»…é‡ç½®WebUIè®¾ç½®, ä¾‹å¦‚UVRæ¨¡å‹è·¯å¾„, WebUIç«¯å£ç­‰ã€‚é‡ç½®WebUIè®¾ç½®å, éœ€è¦é‡å¯WebUIã€‚"))
                    gr.Markdown(i18n("### é‡å¯WebUI"))
                    gr.Markdown(i18n("ç‚¹å‡» â€œé‡å¯WebUIâ€ æŒ‰é’®å, ä¼šçŸ­æš‚æ€§çš„å¤±å»è¿æ¥, éšåä¼šè‡ªåŠ¨å¼€å¯ä¸€ä¸ªæ–°ç½‘é¡µã€‚"))

            restart_webui.click(fn=webui_restart, outputs=setting_output_message)
            check_update.click(fn=check_webui_update, outputs=update_message)
            goto_github.click(fn=webui_goto_github)
            select_uvr_model_dir_button.click(fn=select_folder, outputs=select_uvr_model_dir)
            reset_seetings.click(fn=reset_settings,inputs=[],outputs=setting_output_message)
            reset_all_webui_config.click(fn=reset_webui_config,outputs=setting_output_message)
            set_webui_port.change(fn=save_port_to_config,inputs=[set_webui_port],outputs=setting_output_message)
            select_uvr_model_dir.change(fn=save_uvr_modeldir,inputs=[select_uvr_model_dir],outputs=setting_output_message)
            set_language.change(fn=change_language,inputs=[set_language],outputs=setting_output_message)
            set_download_link.change(fn=change_download_link,inputs=[set_download_link],outputs=setting_output_message)
            open_share_link.change(fn=change_share_link,inputs=[open_share_link],outputs=setting_output_message)
            open_local_link.change(fn=change_local_link,inputs=[open_local_link],outputs=setting_output_message)

local_link = "0.0.0.0" if webui_config["settings"].get("local_link", False) else None
server_port = None if webui_config["settings"].get("port", 0) == 0 else webui_config["settings"].get("port", 0)
isShare = webui_config["settings"].get("share_link", False)
app.launch(inbrowser=True, server_name=local_link, server_port=server_port, share=isShare)
